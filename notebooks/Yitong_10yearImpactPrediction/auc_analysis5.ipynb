{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "#from py2neo.Graph import database \n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "# graph = Graph('bolt://localhost:7687', bolt=True)\n",
    "\n",
    "#graph.delete_all()\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the publications where lang = 'en' and publisher = \"Science\" or \"Nature\" in year 2008\n",
    "import pandas as pd\n",
    "import time\n",
    "print(\"load english science and nature publication into df\")\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "MATCH (n:Quanta) WHERE n.lang = 'en' AND ( n.venue = 'Science' OR n.venue = 'Nature') AND n.year =2008 AND EXISTS(n.fos)\n",
    "RETURN \n",
    "n.venue as venue,\n",
    "n.pageRank_2018 as PR_2018,\n",
    "n.pageRank_2008 as PR_2008,\n",
    "n.fos as fos,\n",
    "n.title as title,\n",
    "n.keywords as keywords,\n",
    "n.publisher as publisher\n",
    "ORDER BY n.pageRank_2018 DESC\n",
    "\"\"\"\n",
    "#n.keywords as keywords\n",
    "dfs_2008_test = graph.run(query).to_data_frame()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "#dfs_2008_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_range = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import itertools\n",
    "\n",
    "dfs_2008_test_copy = dfs_2008_test.copy()\n",
    "start_time = time.time()\n",
    "fos_list = dfs_2008_test_copy[\"fos\"].tolist()\n",
    "fos_list = [[] if v is None else v for v in fos_list]\n",
    "\n",
    "\n",
    "dfs_2008_test_copy.head()\n",
    "#Replace original fos with updated fos \n",
    "dfs_2008_test_copy['fos'] = pd.Series(fos_list).values\n",
    "dfs_2008_test\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(dfs_2008_test_copy.fos)\n",
    "dfs_2008_test_copy = dfs_2008_test_copy.join(pd.DataFrame(X, columns=mlb.classes_))\n",
    "\n",
    "#del fos in the df\n",
    "\n",
    "del dfs_2008_test_copy['fos']\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(dfs_2008_test.title).toarray()\n",
    "#labels = df.category_id\n",
    "print(features.shape)\n",
    "\n",
    "print(len(tfidf.get_feature_names()))\n",
    "print(type(features))\n",
    "\n",
    "title_feature_name = tfidf.get_feature_names()\n",
    "count_featurename = len(title_feature_name)\n",
    "for i in range(count_featurename):\n",
    "    column_name = 'title_'+title_feature_name[i]\n",
    "    dfs_2008_test_copy[column_name] = pd.Series(features[:,i]).values\n",
    "\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(dfs_2008_test_copy['venue'], prefix = 'venue')\n",
    "dfs_2008_test_copy = pd.concat([dfs_2008_test_copy, dfDummies], axis=1)\n",
    "del dfs_2008_test_copy['venue']\n",
    "del dfs_2008_test_copy['keywords']\n",
    "del dfs_2008_test_copy['publisher']\n",
    "del dfs_2008_test_copy['PR_2008']\n",
    "del dfs_2008_test_copy['title']\n",
    "del dfs_2008_test_copy['PR_2018']\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
