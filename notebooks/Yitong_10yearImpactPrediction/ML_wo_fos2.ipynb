{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "#from py2neo.Graph import database \n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "# graph = Graph('bolt://localhost:7687', bolt=True)\n",
    "\n",
    "#graph.delete_all()\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the publications where lang = 'en' and publisher = \"Science\" or \"Nature\" in year 2008\n",
    "import pandas as pd\n",
    "import time\n",
    "print(\"load english science and nature publication into df\")\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "MATCH (n:Quanta) WHERE n.lang = 'en' AND ( n.venue = 'Science' OR n.venue = 'Nature') AND n.year =2008 AND EXISTS(n.fos)\n",
    "RETURN \n",
    "n.venue as venue,\n",
    "n.pageRank_2018 as PR_2018,\n",
    "n.pageRank_2008 as PR_2008,\n",
    "n.fos as fos,\n",
    "n.title as title,\n",
    "n.keywords as keywords,\n",
    "n.publisher as publisher\n",
    "ORDER BY n.pageRank_2018 DESC\n",
    "\"\"\"\n",
    "#n.keywords as keywords\n",
    "dfs_2008_test = graph.run(query).to_data_frame()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "#dfs_2008_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define publiction is popular in 2018 if log(PR_2018) > -0.5 and append the result into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "start_time = time.time()\n",
    "count = len(dfs_2008_test[\"PR_2018\"].tolist())\n",
    "pr_2018_list = dfs_2008_test[\"PR_2018\"].tolist()\n",
    "popular_result = []\n",
    "for pr in pr_2018_list:\n",
    "    if math.log(pr,10) > -0.5:\n",
    "        popular_result.append(1)\n",
    "    else:\n",
    "        popular_result.append(0)\n",
    "\n",
    "print(len(popular_result))\n",
    "\n",
    "dfs_2008_test['popular'] = pd.Series(popular_result).values\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "dfs_2008_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the distribution of high-impact and the rest\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in popular_result:\n",
    "    if i == 1:\n",
    "        count_1 += 1\n",
    "    else:\n",
    "        count_0 += 1\n",
    "print(count_0)\n",
    "print(count_1)\n",
    "print(count_1/len(popular_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration\n",
    "## 2.1 PR_2008 compared to PR_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize histogram bar chart for PR_2018\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "pr_2018_list = dfs_2008_test[\"PR_2018\"].tolist()\n",
    "# %matplotlib inline\n",
    "# plt.hist(pr_2018_list, normed=True, bins=30)\n",
    "# plt.ylabel('Probability');\n",
    "counts, bins, patches = plt.hist(pr_2018_list, bins = 7)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    plt.annotate('{:.2f}'.format(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, 18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the bar without the smallest value\n",
    "pr_2018_smallest = pr_2018_list[-1]\n",
    "pr_2018_list_wo_smallest = []\n",
    "count = 0\n",
    "for pr in pr_2018_list:\n",
    "    if pr>pr_2018_smallest:\n",
    "        pr_2018_list_wo_smallest.append(pr)\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "counts, bins, patches = plt.hist(pr_2018_list_wo_smallest)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    plt.annotate('{:.2f}'.format(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, 18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "plt.show()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualiaze the PageRank distribution after log\n",
    "pr_2018_list_log = []\n",
    "for pr in pr_2018_list:\n",
    "    pr_2018_list_log.append(math.log(pr,10))\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.hist(pr_2018_list, normed=True, bins=30)\n",
    "# plt.ylabel('Probability');\n",
    "counts, bins, patches = plt.hist(pr_2018_list_log,bins = 8)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    plt.annotate('{:.2f}'.format(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, 18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engneering\n",
    "## 3.1 one-hot encoding in fos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import itertools\n",
    "\n",
    "dfs_2008_test_copy = dfs_2008_test.copy()\n",
    "start_time = time.time()\n",
    "fos_list = dfs_2008_test_copy[\"fos\"].tolist()\n",
    "fos_list = [[] if v is None else v for v in fos_list]\n",
    "\n",
    "\n",
    "dfs_2008_test_copy.head()\n",
    "#Replace original fos with updated fos \n",
    "dfs_2008_test_copy['fos'] = pd.Series(fos_list).values\n",
    "dfs_2008_test\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(dfs_2008_test_copy.fos)\n",
    "dfs_2008_test_copy = dfs_2008_test_copy.join(pd.DataFrame(X, columns=mlb.classes_))\n",
    "\n",
    "#del fos in the df\n",
    "\n",
    "del dfs_2008_test_copy['fos']\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 bag of words model for titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(dfs_2008_test.title).toarray()\n",
    "#labels = df.category_id\n",
    "print(features.shape)\n",
    "\n",
    "print(len(tfidf.get_feature_names()))\n",
    "print(type(features))\n",
    "\n",
    "title_feature_name = tfidf.get_feature_names()\n",
    "count_featurename = len(title_feature_name)\n",
    "for i in range(count_featurename):\n",
    "    column_name = 'title_'+title_feature_name[i]\n",
    "    dfs_2008_test_copy[column_name] = pd.Series(features[:,i]).values\n",
    "\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del dfs_2008_test_copy['title']\n",
    "dfs_2008_test_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 one-hot encoding for venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data exploration\n",
    "venue_list = dfs_2008_test_copy[\"venue\"].tolist()\n",
    "popular_list = dfs_2008_test_copy[\"popular\"].tolist()\n",
    "\n",
    "print(dfs_2008_test_copy[\"venue\"].value_counts()[:20])\n",
    "list_len = len(popular_list)\n",
    "nature_count_1 = 0\n",
    "nature_count_0 = 0\n",
    "science_count_1  = 0 \n",
    "science_count_0 = 0 \n",
    "\n",
    "for i in range(list_len):\n",
    "    if venue_list[i] == 'Science' and popular_list[i]==1:\n",
    "        science_count_1 +=1\n",
    "    elif venue_list[i] == 'Science' and popular_list[i]==0:\n",
    "        science_count_0 +=1\n",
    "    elif venue_list[i] == 'Nature' and popular_list[i]==1:\n",
    "        nature_count_1 +=1\n",
    "    else:\n",
    "        nature_count_0 +=1\n",
    "        \n",
    "        \n",
    "print('science_count_1: ' + str(science_count_1))\n",
    "print('science_count_0: ' + str(science_count_0))\n",
    "print('nature_count_1: ' + str(nature_count_1))\n",
    "print('nature_count_0: ' + str(nature_count_0))\n",
    "print('science_1 percentage: ' + str(science_count_1/(science_count_1+science_count_0)))\n",
    "print('nature_1 percentage: ' + str(nature_count_1/(nature_count_1+nature_count_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(dfs_2008_test_copy['venue'], prefix = 'venue')\n",
    "dfs_2008_test_copy = pd.concat([dfs_2008_test_copy, dfDummies], axis=1)\n",
    "del dfs_2008_test_copy['venue']\n",
    "del dfs_2008_test_copy['keywords']\n",
    "del dfs_2008_test_copy['publisher']\n",
    "del dfs_2008_test_copy['PR_2008']\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 2008_2018 conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2008 ranking compare to 2018 ranking \n",
    "\n",
    "title_list = dfs_2008_test[\"title\"].tolist()\n",
    "PR_2008_score_list = dfs_2008_test[\"PR_2008\"].tolist()\n",
    "PR_2018_score_list = dfs_2008_test[\"PR_2018\"].tolist()\n",
    "\n",
    "# create the ranking list of 2018\n",
    "sort_unique_2018 = sorted(set(PR_2018_score_list))\n",
    "dic_2018_rank = {}\n",
    "count = 0\n",
    "for i in sort_unique_2018:\n",
    "    dic_2018_rank[i] = len(sort_unique_2018)-count\n",
    "    count += 1\n",
    "PR_2018_rank_list = [] \n",
    "for i in PR_2018_score_list:\n",
    "    PR_2018_rank_list.append(dic_2018_rank[i])\n",
    "\n",
    "# create the ranking list of 2008\n",
    "sort_unique_2008 = sorted(set(PR_2008_score_list))\n",
    "dic_2008_rank = {}\n",
    "count = 0\n",
    "for i in sort_unique_2008:\n",
    "    dic_2008_rank[i] = len(sort_unique_2008)-count\n",
    "    count += 1\n",
    "PR_2008_rank_list = [] \n",
    "for i in PR_2008_score_list:\n",
    "    PR_2008_rank_list.append(dic_2008_rank[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualization 2 list\n",
    "\n",
    "id_2018 = []\n",
    "for i in range(len(PR_2008_score_list)):\n",
    "    id_2018.append(i)\n",
    "\n",
    "plt.plot(id_2018, PR_2018_rank_list, color='g')\n",
    "plt.plot(id_2018, PR_2008_rank_list, color='orange')\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('PageRank Impact Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2018 = []\n",
    "for i in range(len(PR_2008_score_list)):\n",
    "    id_2018.append(i)\n",
    "\n",
    "plt.plot(id_2018[:200], PR_2018_rank_list[:200], color='g')\n",
    "plt.plot(id_2018[:200], PR_2008_rank_list[:200], color='orange')\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('PageRank Impact Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Model Construction\n",
    "## 4.1 Random forest\n",
    "### 4.1.1 random forest with featured venue, title and fos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_2018 = dfs_2008_test[\"popular\"].tolist()\n",
    "del dfs_2008_test_copy['popular']\n",
    "del dfs_2008_test_copy['PR_2018']\n",
    "dfs_2008_test_copy['popular'] = pd.Series(popular_2018).values\n",
    "dfs_2008_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the comlumn list\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_list = list(dfs_2008_test_copy.columns.values)\n",
    "# split train and test\n",
    "df_X = dfs_2008_test_copy[feature_list[:-1]]\n",
    "df_y = dfs_2008_test_copy['popular']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)\n",
    "tp = conf[0][0]\n",
    "fp = conf[0][1]\n",
    "fn = conf[1][0]\n",
    "tn = conf[1][1]\n",
    "\n",
    "print('sensitivity: ')\n",
    "print(tp/(tp+fn))\n",
    "print('sprcificity: ')\n",
    "print(tn/(fp+tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Add 2008 pagerank score into features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfs_2008_test_copy['popular']\n",
    "dfs_2008_test_copy['PR_2008'] = pd.Series(PR_2008_score_list).values\n",
    "dfs_2008_test_copy['popular'] = pd.Series(popular_2018).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "feature_list = list(dfs_2008_test_copy.columns.values)\n",
    "# split train and test\n",
    "df_X = dfs_2008_test_copy[feature_list[:-1]]\n",
    "df_y = dfs_2008_test_copy['popular']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=99)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)\n",
    "tp = conf[0][0]\n",
    "fp = conf[0][1]\n",
    "fn = conf[1][0]\n",
    "tn = conf[1][1]\n",
    "\n",
    "print('sensitivity: ')\n",
    "print(tp/(tp+fn))\n",
    "print('specificity: ')\n",
    "print(tn/(fp+tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment: we could see that the PR_score in the pulished year could improve the accuracy for the next ten years\n",
    "## However, the problem here is we for some publications published in Dec, it might not have rnough time to acculumate \n",
    "## the PR score.\n",
    "\n",
    "#cross validation\n",
    "from sklearn import tree\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid = {'min_samples_split':[5,6,7],\n",
    "             'n_estimators': [80,100,120]}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, cv=3, n_jobs =1, refit = False )\n",
    "grid_search.fit(X = df_X, y = df_y)\n",
    "\n",
    "print(grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "\n",
    "# plays fine in cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Logistic regression\n",
    "### 4.2.1 with fos venue and title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfs_2008_test_copy['PR_2008']\n",
    "dfs_2008_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "feature_list = list(dfs_2008_test_copy.columns.values)\n",
    "# split train and test\n",
    "df_X = dfs_2008_test_copy[feature_list[:-1]]\n",
    "df_y = dfs_2008_test_copy['popular']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=99)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)\n",
    "tp = conf[0][0]\n",
    "fp = conf[0][1]\n",
    "fn = conf[1][0]\n",
    "tn = conf[1][1]\n",
    "\n",
    "print('sensitivity: ')\n",
    "print(tp/(tp+fn))\n",
    "print('sprcificity: ')\n",
    "print(tn/(fp+tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfs_2008_test_copy['popular']\n",
    "dfs_2008_test_copy['PR_2008'] = pd.Series(PR_2008_score_list).values\n",
    "dfs_2008_test_copy['popular'] = pd.Series(popular_2018).values\n",
    "dfs_2008_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(dfs_2008_test_copy.columns.values)\n",
    "# split train and test\n",
    "df_X = dfs_2008_test_copy[feature_list[:-1]]\n",
    "df_y = dfs_2008_test_copy['popular']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=99)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)\n",
    "tp = conf[0][0]\n",
    "fp = conf[0][1]\n",
    "fn = conf[1][0]\n",
    "tn = conf[1][1]\n",
    "\n",
    "print('sensitivity: ')\n",
    "print(tp/(tp+fn))\n",
    "print('sprcificity: ')\n",
    "print(tn/(fp+tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_array = dfs_2008_test_copy.values\n",
    "print(value_array.shape)\n",
    "y = value_array[:, -1]\n",
    "# print(y)\n",
    "X = value_array[:, :-1]\n",
    "print(X.shape)\n",
    "print(len(X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#Initializing Neural Network\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = len(X[1])))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn = cm[1][1]\n",
    "\n",
    "print('sensitivity: ')\n",
    "print(tp/(tp+fn))\n",
    "print('specificity: ')\n",
    "print(tn/(fp+tn))\n",
    "\n",
    "print('accuracy: ')\n",
    "print((tp+tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "nn_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test))\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='NN Regression (area = %0.2f)' % nn_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Neural Network ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
