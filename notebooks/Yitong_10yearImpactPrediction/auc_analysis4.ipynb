{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "#from py2neo.Graph import database \n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "# graph = Graph('bolt://localhost:7687', bolt=True)\n",
    "\n",
    "#graph.delete_all()\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the publications where lang = 'en' and publisher = \"Science\" or \"Nature\" in year 2008\n",
    "import pandas as pd\n",
    "import time\n",
    "print(\"load english science and nature publication into df\")\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "MATCH (n:Quanta) WHERE n.lang = 'en' AND ( n.venue = 'Science' OR n.venue = 'Nature') AND n.year =2008 AND EXISTS(n.fos)\n",
    "RETURN \n",
    "n.venue as venue,\n",
    "n.pageRank_2018 as PR_2018,\n",
    "n.pageRank_2008 as PR_2008,\n",
    "n.fos as fos,\n",
    "n.title as title,\n",
    "n.keywords as keywords,\n",
    "n.publisher as publisher\n",
    "ORDER BY n.pageRank_2018 DESC\n",
    "\"\"\"\n",
    "#n.keywords as keywords\n",
    "dfs_2008_test = graph.run(query).to_data_frame()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "#dfs_2008_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_range = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import itertools\n",
    "\n",
    "dfs_2008_test_copy = dfs_2008_test.copy()\n",
    "start_time = time.time()\n",
    "fos_list = dfs_2008_test_copy[\"fos\"].tolist()\n",
    "fos_list = [[] if v is None else v for v in fos_list]\n",
    "\n",
    "\n",
    "dfs_2008_test_copy.head()\n",
    "#Replace original fos with updated fos \n",
    "dfs_2008_test_copy['fos'] = pd.Series(fos_list).values\n",
    "dfs_2008_test\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(dfs_2008_test_copy.fos)\n",
    "dfs_2008_test_copy = dfs_2008_test_copy.join(pd.DataFrame(X, columns=mlb.classes_))\n",
    "\n",
    "#del fos in the df\n",
    "\n",
    "del dfs_2008_test_copy['fos']\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(dfs_2008_test.title).toarray()\n",
    "#labels = df.category_id\n",
    "print(features.shape)\n",
    "\n",
    "print(len(tfidf.get_feature_names()))\n",
    "print(type(features))\n",
    "\n",
    "title_feature_name = tfidf.get_feature_names()\n",
    "count_featurename = len(title_feature_name)\n",
    "for i in range(count_featurename):\n",
    "    column_name = 'title_'+title_feature_name[i]\n",
    "    dfs_2008_test_copy[column_name] = pd.Series(features[:,i]).values\n",
    "\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(dfs_2008_test_copy['venue'], prefix = 'venue')\n",
    "dfs_2008_test_copy = pd.concat([dfs_2008_test_copy, dfDummies], axis=1)\n",
    "del dfs_2008_test_copy['venue']\n",
    "del dfs_2008_test_copy['keywords']\n",
    "del dfs_2008_test_copy['publisher']\n",
    "del dfs_2008_test_copy['PR_2008']\n",
    "del dfs_2008_test_copy['title']\n",
    "del dfs_2008_test_copy['PR_2018']\n",
    "dfs_2008_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "def rf_auc(df, top_pt):\n",
    "    \n",
    "    if 'popular' in df:\n",
    "        del df['popular']\n",
    "    \n",
    "    row_n = len(df)\n",
    "    index = row_n*top_pt\n",
    "    \n",
    "    popular_result = []\n",
    "    for i in range(row_n):\n",
    "        if i < index:\n",
    "            popular_result.append(1)\n",
    "        else:\n",
    "            popular_result.append(0)\n",
    "    \n",
    "    df['popular'] = pd.Series(popular_result).values\n",
    "    #finished setting up models \n",
    "    feature_list = list(df.columns.values)\n",
    "    df_X = df[feature_list[:-1]]\n",
    "    df_y = df['popular']\n",
    "    \n",
    "    \n",
    "            \n",
    "    clf = RandomForestClassifier(min_samples_split =7, n_estimators=100)\n",
    "    mean_auc = []\n",
    "    n = 4  # repeat the CV procedure 10 times to get more precise results\n",
    "    for i in range(n):\n",
    "        # for each iteration, randomly hold out 20% of the data as CV set\n",
    "        X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "        df_X, df_y, test_size=.20, random_state=99)\n",
    "\n",
    "        # train model and make predictions\n",
    "        clf.fit(X_train, y_train) \n",
    "        preds = clf.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "        # compute AUC metric for this CV fold\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print (\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "        mean_auc.append(roc_auc )\n",
    "\n",
    "    print (\"Mean AUC: %f\" % ( np.mean(mean_auc)))\n",
    "    print (\"std AUC: %f\" % np.std(mean_auc))\n",
    "    return (np.mean(mean_auc),np.std(mean_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "def lg_auc(df, top_pt):\n",
    "    if 'popular' in df:\n",
    "        del df['popular']\n",
    "    \n",
    "    row_n = len(df)\n",
    "    index = row_n*top_pt\n",
    "    \n",
    "    popular_result = []\n",
    "    for i in range(row_n):\n",
    "        if i < index:\n",
    "            popular_result.append(1)\n",
    "        else:\n",
    "            popular_result.append(0)\n",
    "    \n",
    "    df['popular'] = pd.Series(popular_result).values\n",
    "    #finished setting up models \n",
    "    feature_list = list(df.columns.values)\n",
    "    df_X = df[feature_list[:-1]]\n",
    "    df_y = df['popular']\n",
    "    \n",
    "    \n",
    "            \n",
    "    clf = LogisticRegression()\n",
    "    mean_auc = []\n",
    "    n = 4  # repeat the CV procedure 10 times to get more precise results\n",
    "    for i in range(n):\n",
    "        # for each iteration, randomly hold out 20% of the data as CV set\n",
    "        X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "        df_X, df_y, test_size=.20, random_state=99)\n",
    "\n",
    "        # train model and make predictions\n",
    "        clf.fit(X_train, y_train) \n",
    "        preds = clf.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "        # compute AUC metric for this CV fold\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print (\"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc))\n",
    "        mean_auc.append(roc_auc )\n",
    "\n",
    "    print (\"Mean AUC: %f\" % ( np.mean(mean_auc)))\n",
    "    print (\"std AUC: %f\" % np.std(mean_auc))\n",
    "    return (np.mean(mean_auc),np.std(mean_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_list = []\n",
    "lg_list = []\n",
    "\n",
    "\n",
    "for i in top_range:\n",
    "    print('currently running top: ' + str(i))\n",
    "    \n",
    "#     rf_result = rf_auc(dfs_2008_test_copy,i)\n",
    "#     rf_list.append(rf_result)\n",
    "    \n",
    "    lg_result = lg_auc(dfs_2008_test_copy,i)\n",
    "    lg_list.append(lg_result)\n",
    "    \n",
    "    #lg_list = lf_auc(dfs_2008_test_copy,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def nn_auc(df, top_pt):\n",
    "    if 'popular' in df:\n",
    "        del df['popular']\n",
    "    \n",
    "    row_n = len(df)\n",
    "    index = row_n*top_pt\n",
    "    \n",
    "    popular_result = []\n",
    "    for i in range(row_n):\n",
    "        if i < index:\n",
    "            popular_result.append(1)\n",
    "        else:\n",
    "            popular_result.append(0)\n",
    "        \n",
    "    df['popular'] = pd.Series(popular_result).values\n",
    "    \n",
    "    value_array = df.values\n",
    "    print(value_array.shape)\n",
    "    y = value_array[:, -1]\n",
    "    X = value_array[:, :-1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "   \n",
    "    #Initializing Neural Network\n",
    "    classifier = Sequential()\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = len(X[1])))\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "    \n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting our model \n",
    "    classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 40)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    tp = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tn = cm[1][1]\n",
    "    \n",
    "    auc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_list = []\n",
    "for i in top_range:\n",
    "    nn_result = nn_auc(dfs_2008_test_copy,i)\n",
    "    nn_list.append(nn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( nn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score = []\n",
    "lg_score = []\n",
    "nn_score = nn_list\n",
    "\n",
    "for i in range(len(top_range)):\n",
    "    rf_score.append(rf_list[i][0])\n",
    "    lg_score.append(lg_list[i][0])\n",
    "    \n",
    "print(rf_score)\n",
    "print(lg_score)\n",
    "print(nn_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = top_range\n",
    "y = [rf_score,lg_score,nn_score]\n",
    "plt.xlabel(\"Default top percentage\")\n",
    "plt.ylabel(\"auc\")\n",
    "plt.title(\"top-pct to auc\")\n",
    "\n",
    "plt.plot(x,y[0],label = 'rf')\n",
    "plt.plot(x,y[1],label = 'lg')\n",
    "plt.plot(x,y[2],label = 'nn')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score_modified = []\n",
    "lg_score_modified = []\n",
    "nn_score_modified = []\n",
    "\n",
    "for i in range(len(top_range)):\n",
    "    base = max(top_range[i], 1-top_range[i])\n",
    "    rf_score_modified.append(rf_score[i] - base)\n",
    "    lg_score_modified.append(lg_score[i] - base)\n",
    "    nn_score_modified.append(nn_score[i] - base)\n",
    "    \n",
    "    \n",
    "x = top_range\n",
    "plt.xlabel(\"Default top percentage\")\n",
    "plt.ylabel(\"modified auc\")\n",
    "plt.title(\"top-pct to auc\")\n",
    "\n",
    "plt.plot(x,rf_score_modified,label = 'rf_modified')\n",
    "plt.plot(x,lg_score_modified,label = 'lg_modified')\n",
    "plt.plot(x,nn_score_modified,label = 'nn_modified')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
