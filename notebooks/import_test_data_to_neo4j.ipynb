{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship \n",
    "\n",
    "graph = Graph('bolt://localhost:7687', auth=('neo4j', 'password'))\n",
    "\n",
    "graph.delete_all()\n",
    "\n",
    "#n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "#n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "#print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     #(n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating uniqueness constraint (and also index) on Quanta id's... Done.\n",
      "Creating uniqueness constraint (and also index) on Author names... Done.\n",
      "Creating uniqueness constraint (and also index) on Organization names... Done.\n"
     ]
    }
   ],
   "source": [
    "# Constrain one id per Quanta\n",
    "print(\"Creating uniqueness constraint (and also index) on Quanta id's...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (n:Quanta) ASSERT n.id IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Constrain one name per author\n",
    "print(\"Creating uniqueness constraint (and also index) on Author names...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Constrain one name per organization\n",
    "print(\"Creating uniqueness constraint (and also index) on Organization names...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (o:Organization) ASSERT o.name IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index for publication year... Done.\n",
      "Creating index for langauge... Done.\n",
      "Creating index for fos... Done.\n",
      "Creating index for title... Done.\n"
     ]
    }
   ],
   "source": [
    "# Add index for year of publication\n",
    "print(\"Creating index for publication year...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(year);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for language\n",
    "print(\"Creating index for langauge...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(lang);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for keywords HOW?\n",
    "print(\"Creating index for fos...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(fos);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for title (good idea?)\n",
    "print(\"Creating index for title...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(title);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x104f0e4e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_query = \"\"\"\n",
    "CALL apoc.load.json('file:/Users/timholds/code/scaling-science/notebooks/data/fake-data.txt') YIELD value AS q UNWIND q.id AS id UNWIND q.authors as authors\n",
    "MERGE (a:Author {name:authors.name})\n",
    "WITH a, q, authors\n",
    "WHERE authors.org is not null\n",
    "MERGE (i:Quanta {id:q.id}) ON CREATE SET i.year=q.year, i.title=q.title, i.fos=q.fos\n",
    "WITH q.id AS id, head(q.authors).name as firstName, last(q.authors).name as lastName, q.authors as authors\n",
    "UNWIND authors as author\n",
    "MATCH (i:Quanta {id:id}) \n",
    "MATCH (a:Author {name:author.name})\n",
    "WITH i, a, author.name = firstName as isFirstName, author.name = lastName as isLastName\n",
    "MERGE (a)-[:AUTHORED {is_first_author:isFirstName, is_last_author:isLastName}]-(i)\n",
    "RETURN *\n",
    "\"\"\"\n",
    "\n",
    "graph.run(import_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x104f0e588>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test citation relationships\n",
    "query1 = \"\"\"\n",
    "Match (a:Quanta {title: \"Paper13\"})\n",
    "Match (b:Quanta {title: \"Paper7\"})\n",
    "WITH a, b\n",
    "MERGE (a)-[:CITES]->(b)\"\"\"\n",
    "graph.run(query1)\n",
    "\n",
    "query2 = \"\"\"\n",
    "Match (c:Quanta {title: \"Paper13\"})\n",
    "Match (d:Quanta {title: \"Paper1\"})\n",
    "WITH c, d\n",
    "MERGE (c)-[:CITES]->(d)\n",
    "\"\"\"\n",
    "graph.run(query2)\n",
    "\n",
    "query3 = \"\"\"\n",
    "Match (e:Quanta {title: \"Paper7\"})\n",
    "Match (f:Quanta {title: \"Paper1\"})\n",
    "WITH e, f\n",
    "MERGE (e)-[:CITES]->(f)\n",
    "\"\"\"\n",
    "graph.run(query3)\n",
    "\n",
    "query4 = \"\"\"\n",
    "Match (g:Quanta {title: \"Paper13\"})\n",
    "Match (h:Quanta {title: \"Paper8\"})\n",
    "WITH g, h\n",
    "MERGE (g)-[:CITES]->(h)\n",
    "\"\"\"\n",
    "graph.run(query4)\n",
    "\n",
    "query5 = \"\"\"\n",
    "Match (i:Quanta {title: \"Paper7\"})\n",
    "Match (j:Quanta {title: \"Paper8\"})\n",
    "WITH i, j\n",
    "MERGE (i)-[:CITES]->(j)\n",
    "\"\"\"\n",
    "graph.run(query5)\n",
    "\n",
    "query6 = \"\"\"\n",
    "Match (k:Quanta {title: \"Paper1\"})\n",
    "Match (l:Quanta {title: \"Paper8\"})\n",
    "WITH k, l\n",
    "MERGE (k)-[:CITES]->(l)\n",
    "\n",
    "\"\"\"\n",
    "graph.run(query6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x104f46ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_extra_query = \"\"\"\n",
    "MATCH (n)\n",
    "WHERE size((n)--())=0\n",
    "DELETE (n)\"\"\"\n",
    "graph.run(delete_extra_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STOP HERE: the cells after this are not needed for importing test data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"STOP HERE: the cells after this are not needed for importing test data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fastest: Put more work on thread running in parallel. \n",
    "print(\"Adding citation relationships...\", end=\" \", flush=True)\n",
    "# query = \"\"\"\n",
    "# MATCH (b:Quanta) UNWIND b.refs AS ref\n",
    "# MATCH (a:Quanta {id: ref}) MERGE (b)-[:CITES]->(a);\n",
    "# \"\"\"\n",
    "\n",
    "Note this query ^^ should include the apoc.periodic.iterate() function, which would be:\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "\"MATCH (b:Quanta) UNWIND b.refs AS ref RETURN b, ref\",\n",
    "\"MATCH (a:Quanta {id: ref}) MERGE (b)-[:CITES]->(a)\",\n",
    "{batchSize:500, iterateList:true, parallel:false});\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created graph database with 22 nodes and 46 relationships!\n"
     ]
    }
   ],
   "source": [
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Created graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various misc scripts below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PageRank on works from <= 1985... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1986... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1987... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1988... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1989... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1990... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1991... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1992... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1993... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1994... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1995... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1996... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1997... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1998... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 1999... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2000... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2001... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2002... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2003... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2004... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2005... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2006... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2007... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2008... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2009... Pulling out and saving results... Done.\n",
      "Running PageRank on works from <= 2010... Pulling out and saving results... Done.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'a.pageRank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d60723165048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a.title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a.pageRank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[1;32m   4443\u001b[0m                            \u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4444\u001b[0m                            \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4445\u001b[0;31m                            margins_name=margins_name)\n\u001b[0m\u001b[1;32m   4446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mto_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a.pageRank'"
     ]
    }
   ],
   "source": [
    "# Run PageRank on each year from 1800 to 1805\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "start_year, end_year = 1985, 2010\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1):\n",
    "\n",
    "    print(\"Running PageRank on works from <= {}...\".format(year), end=\" \")\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank(\n",
    "    'MATCH (p:Quanta) WHERE p.year <= {} RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', writeProperty:'pageRank_{}', iterations:5, write: true, concurrency:20}});\n",
    "    \"\"\".format(year,year)\n",
    "    graph.run(query).evaluate()\n",
    "    \n",
    "    print(\"Pulling out and saving results...\", end=\" \")\n",
    "    query = \"\"\"\n",
    "    MATCH (a:Quanta) \n",
    "    WHERE a.year <= {} \n",
    "    RETURN id(a), a.title, a.pageRank_{}\"\"\".format(year,year)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "    print(\"Done.\")\n",
    "    \n",
    "result = pd.concat(dfs).pivot_table(index='a.title', columns='year', values='a.pageRank')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat(dfs).pivot_table(index='a.title', columns='year', values='a.pageRank')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write result to CSV\n",
    "file_path = '/tmp/data/result/impact_20M_{}-{}.csv'.format(start_year, end_year)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.index = result.index.str.replace(\",\",\"\")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "scores = result.sum(axis=1)\n",
    "scores.plot.hist(grid=True,bins=[i/2 for i in range(1,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_threshold = scores.quantile(0.999999)\n",
    "top_papers = scores.drop(scores[scores.values>=15].index)\n",
    "print(\"Considering the top {} (score >= {:.2f}) papers.\".format(len(top_papers), score_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "word_lists = top_papers.index.to_series().apply(\n",
    "    lambda x: [w for w in re.compile(r\"[A-Za-z']{4,}\").findall(x)])\n",
    "all_words = set()\n",
    "word_map = {}\n",
    "for i,v in word_lists.items():\n",
    "    for w in v:\n",
    "        all_words.add(w.lower())\n",
    "        word_map.get(w,[]).append(i)\n",
    "print(\"Built set and map of {:,} unique words.\".format(len(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Filling {}x{} dataframe...\".format(len(all_words),len(result.columns)), end = \"\")\n",
    "word_scores = pd.DataFrame(0, index=all_words, columns=result.columns)\n",
    "for key, value in word_map:\n",
    "    print(key)\n",
    "#     for w in ws:\n",
    "#         print(w)\n",
    "#         word_scores.loc[w.lower()] += result.loc[title].va\n",
    "#         print(word_scores.loc[w.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_scores[title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.loc[title,:]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
