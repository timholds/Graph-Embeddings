{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to graph database with 278,432,359 nodes and 1,817,035,911 relationships!\n"
     ]
    }
   ],
   "source": [
    "graph = Graph(\"bolt://neo4j-quanta:7687\", auth=('neo4j','myneo'))\n",
    "\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format(\n",
    "    graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "    graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_df(query, graph):\n",
    "    print(\"Starting query...\", end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query... "
     ]
    }
   ],
   "source": [
    "# Number of Early Adopters by Year\n",
    "#\n",
    "# NOTE limitation on q.year to speed test run time.\n",
    "# Eventually will need to write to CSV and process in batches. \n",
    "#\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)-[:CITES]->(q:Quanta)\n",
    "WHERE p.year < q.year + 4 AND q.year > 2017\n",
    "WITH *, q.year+1 as p1, q.year+2 as p2, q.year+3 as p3\n",
    "WITH q.title as title, p1, p2, p3, q.year as qyear, apoc.coll.toSet(collect({name:a.name, year:p.year})) AS alist\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year=p1 | x.name]) AS year_1\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year=p2 and not x.name in year_1 | x.name]) AS year_2\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year=p3 and not x.name in year_1 and not x.name in year_2 | x.name]) AS year_3\n",
    "return \n",
    "    title, \n",
    "    size(year_1) as early_adopters_1, \n",
    "    size(year_2) as early_adopters_2,\n",
    "    size(year_3) as early_adopters_3\"\"\"\n",
    "\n",
    "df_earlyadopters = query_to_df(query, graph)\n",
    "df_earlyadopters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Uninfected Neighbors of Early Adopters\n",
    "#\n",
    "# NOTE limitation on q.year to speed test run time.\n",
    "# Eventually will need to write to CSV and process in batches. \n",
    "#\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)-[:CITES]->(q:Quanta)\n",
    "WHERE p.year < q.year + 4 AND q.year > 2017\n",
    "WITH *, q.year+1 as p1, q.year+2 as p2, q.year+3 as p3\n",
    "WITH q.title as title, p1, p2, p3, q.year as qyear, \n",
    "    apoc.coll.toSet(collect({person:a, year:p.year})) AS alist\n",
    "// alist is people who have ever cited TITLE within 3 years of TITLE being published\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p1|x.person]) AS year_1\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p2|x.person]) AS year_2\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p3|x.person]) AS year_3\n",
    "// year_3 is the set of people who has written a paper that cites TITLE within 3 years of TITLE being published\n",
    "\n",
    "MATCH (n:PhysicsAuthor)-[:COAUTHOR]-(b:PhysicsAuthor)\n",
    "WHERE b IN year_3\n",
    "WITH *, COLLECT(n) AS nlist\n",
    "WITH *, apoc.coll.toSet([x in nlist where b in year_1 and not x in year_1 | x.name]) AS y1_neighbors\n",
    "WITH *, apoc.coll.toSet([x in nlist where b in year_2 and not x in year_2 | x.name]) AS y2_neighbors\n",
    "WITH *, apoc.coll.toSet([x in nlist where b in year_3 and not x in year_3 | x.name]) AS y3_neighbors\n",
    "RETURN \n",
    "    title, \n",
    "    sum(size(y1_neighbors)) as neighbors_1, \n",
    "    sum(size(y2_neighbors)) as neighbors_2, \n",
    "    sum(size(y3_neighbors)) as neighbors_3\"\"\"\n",
    "\n",
    "df_uninfectedneighbors = query_to_df(query, graph)\n",
    "df_uninfectedneighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query... Done (0.48 minutes).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infected_communities_1</th>\n",
       "      <th>infected_communities_2</th>\n",
       "      <th>infected_communities_3</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>On end to end network slicing for 5G communica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How Light Is Emitted by Plasmonic Metals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Molecular characterization of NRXN1 deletions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>“Christmas Balls”: a Christmas carol by the ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Systematic testing of enzyme perturbation sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   infected_communities_1  infected_communities_2  infected_communities_3  \\\n",
       "0                       1                       1                       1   \n",
       "1                       2                       2                       2   \n",
       "2                       1                       1                       1   \n",
       "3                       1                       1                       1   \n",
       "4                       2                       2                       2   \n",
       "\n",
       "                                               title  \n",
       "0  On end to end network slicing for 5G communica...  \n",
       "1           How Light Is Emitted by Plasmonic Metals  \n",
       "2  Molecular characterization of NRXN1 deletions ...  \n",
       "3  “Christmas Balls”: a Christmas carol by the ad...  \n",
       "4  Systematic testing of enzyme perturbation sens...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Infected Communities\n",
    "#\n",
    "# NOTE limitation on q.year to speed test run time.\n",
    "# Eventually will need to write to CSV and process in batches. \n",
    "#\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)-[:CITES]->(q:Quanta)\n",
    "WHERE p.year < q.year + 4 AND q.year>2016\n",
    "WITH *, q.year+1 as p1, q.year+2 as p2, q.year+3 as p3\n",
    "WITH q.title as title, p1, p2, p3, q.year as qyear, apoc.coll.toSet(collect({person:a, year:p.year})) AS alist\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p1|head(x.person.louvain)]) AS year_1\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p2|head(x.person.louvain)]) AS year_2\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p3|head(x.person.louvain)]) AS year_3\n",
    "RETURN \n",
    "    title, \n",
    "    size(year_1) as infected_communities_1, \n",
    "    size(year_2) as infected_communities_2, \n",
    "    size(year_3) as infected_communities_3\"\"\"\n",
    "\n",
    "df_infectedcommunities = query_to_df(query, graph)\n",
    "df_infectedcommunities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Entropy\n",
    "#\n",
    "# NOTE limitation on q.year to speed test run time.\n",
    "# Eventually will need to write to CSV and process in batches. \n",
    "#\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)-[:CITES]->(q:Quanta)\n",
    "WHERE p.year < q.year + 4 AND q.year>2017\n",
    "WITH \n",
    "    q, q.title as title, \n",
    "    apoc.coll.toSet(collect({paper:p, community:last(a.louvain)})) as clist, \n",
    "    q.year+1 as p1, q.year+2 as p2, q.year+3 as p3\n",
    "WITH *, apoc.coll.frequencies([x IN clist WHERE x.paper.year<=p1|x.community]) AS year_1_count, size(apoc.coll.toSet([x IN clist WHERE x.paper.year<=p1|x.paper])) as s1\n",
    "WITH *, apoc.coll.frequencies([x IN clist WHERE x.paper.year<=p2|x.community]) AS year_2_count, size(apoc.coll.toSet([x IN clist WHERE x.paper.year<=p2|x.paper])) as s2\n",
    "WITH *, apoc.coll.frequencies([x IN clist WHERE x.paper.year<=p3|x.community]) AS year_3_count, size(apoc.coll.toSet([x IN clist WHERE x.paper.year<=p3|x.paper])) as s3\n",
    "RETURN \n",
    "    title, \n",
    "    reduce(i = 0.0, x IN year_1_count| i - toFloat(x.count)/s1*log(toFloat(x.count)/s1)/log(2)) as usage_entropy_1,\n",
    "    reduce(i = 0.0, x IN year_2_count| i - toFloat(x.count)/s2*log(toFloat(x.count)/s2)/log(2)) as usage_entropy_2,\n",
    "    reduce(i = 0.0, x IN year_3_count| i - toFloat(x.count)/s3*log(toFloat(x.count)/s3)/log(2)) as usage_entropy_3\"\"\"\n",
    "\n",
    "df_usageentropy = query_to_df(query, graph)\n",
    "df_usageentropy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adoption Entropy\n",
    "#\n",
    "# NOTE limitation on q.year to speed test run time.\n",
    "# Eventually will need to write to CSV and process in batches. \n",
    "#\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)-[:CITES]->(q:Quanta)\n",
    "WHERE p.year < q.year + 4 AND q.year>2017\n",
    "WITH *, q.year+1 as p1, q.year+2 as p2, q.year+3 as p3\n",
    "WITH q.title as title, p1, p2, p3, \n",
    "    apoc.coll.toSet(collect({person:a, year:p.year})) AS alist\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p1|x.person]) AS year_1_people\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p2|x.person]) AS year_2_people\n",
    "WITH *, apoc.coll.toSet([x IN alist WHERE x.year<=p3|x.person]) AS year_3_people\n",
    "WITH *, apoc.coll.frequencies([x IN year_1_people | head(x.louvain)]) AS year_1_count, size(year_1_people) as s1\n",
    "WITH *, apoc.coll.frequencies([x IN year_2_people | head(x.louvain)]) AS year_2_count, size(year_2_people) as s2\n",
    "WITH *, apoc.coll.frequencies([x IN year_3_people | head(x.louvain)]) AS year_3_count, size(year_3_people) as s3\n",
    "RETURN \n",
    "    title, \n",
    "    reduce(i = 0.0, x IN year_1_count| i - toFloat(x.count)/s1*log(toFloat(x.count)/s1)/log(2)) as adoption_entropy_1,\n",
    "    reduce(i = 0.0, x IN year_2_count| i - toFloat(x.count)/s2*log(toFloat(x.count)/s2)/log(2)) as adoption_entropy_2, \n",
    "    reduce(i = 0.0, x IN year_3_count| i - toFloat(x.count)/s3*log(toFloat(x.count)/s3)/log(2)) as adoption_entropy_3\"\"\"\n",
    "\n",
    "df_adoptionentropy = query_to_df(query, graph)\n",
    "df_adoptionentropy.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
