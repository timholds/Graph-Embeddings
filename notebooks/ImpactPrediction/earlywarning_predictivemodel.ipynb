{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://neo4j-quanta:7687\", auth=('neo4j','myneo'))\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format(\n",
    "    graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "    graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_use = 3\n",
    "start_year = 2009\n",
    "end_year = 2013\n",
    "\n",
    "print(\"Getting dataset...\", end=\" \")\n",
    "cites_str = ',\\n    '.join(['CASE WHEN {} < q.year THEN NULL ELSE SIZE((q)<-[:CITES]-(:Quanta {{year: {}}})) END as c{}'.format(\n",
    "    yr, yr, yr) for yr in range(start_year, end_year+1)])\n",
    "tspr_str = ',\\n    '.join(['q.tspr{} as tspr{}'.format(\n",
    "    yr, yr) for yr in range(start_year, end_year+1)])\n",
    "query = \"\"\"\n",
    "MATCH (q:Quanta)\n",
    "WHERE \n",
    "    (q.doctype='Journal') AND \n",
    "    (q.lang='en') AND \n",
    "    EXISTS(q.fos) AND \n",
    "    (q.year>={} AND q.year <= {}) \n",
    "RETURN\n",
    "    q.year as year,\n",
    "    q.title as title,\n",
    "    q.id as id,\n",
    "    {},\n",
    "    {}\n",
    "LIMIT 1000\n",
    "\"\"\".format(start_year, end_year-years_to_use, tspr_str, cites_str)\n",
    "print(query)\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['year','title','id']]\n",
    "\n",
    "for i in range(years_to_use+1):\n",
    "    df_new['c{}'.format(i)] = df.apply(lambda row: row['c{}'.format(row['year']+i)], axis=1)\n",
    "    df_new['p{}'.format(i)] = df.apply(lambda row: row['tspr{}'.format(row['year']+i)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns\n",
    "cs = ['c{}'.format(x) for x in range(years_to_use+1)]\n",
    "ps = ['p{}'.format(x) for x in range(years_to_use+1)]\n",
    "cs.extend(ps)\n",
    "X = df_new[cs]\n",
    "y = df_new['p{}'.format(years_to_use)] >= df_new['p{}'.format(years_to_use)].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal, y_bal = balanced_subsample(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df_new['p6'] >= df_new['p6'].quantile(0.90)\n",
    "#X = df_new[['c1','c2','c3']].values\n",
    "#X = df_new[['p1','p2','p3']].values\n",
    "# X = df_new[['p1','p2','p3','c1','c2','c3']].values\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf, X_bal, y_bal, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
