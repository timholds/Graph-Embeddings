{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://neo4j-allquanta:7687\", auth=('neo4j','myneo'))\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format(\n",
    "    graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "    graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_use = 3\n",
    "start_year = 1950\n",
    "end_year = 2018\n",
    "\n",
    "print(\"Getting dataset...\", end=\" \")\n",
    "cites_str = ',\\n    '.join(['CASE WHEN {} < q.year THEN NULL ELSE SIZE((q)<-[:CITES]-(:Quanta {{year: {}}})) END as c{}'.format(\n",
    "    yr, yr, yr) for yr in range(start_year, end_year+1)])\n",
    "tspr_str = ',\\n    '.join(['q.tspr{} as tspr{}'.format(\n",
    "    yr, yr) for yr in range(start_year, end_year+1)])\n",
    "query = \"\"\"\n",
    "MATCH (q:Quanta)\n",
    "WHERE \n",
    "    (q.year>={} AND q.year <= {} AND q.venue=\"Nature\") \n",
    "RETURN\n",
    "    q.year as year,\n",
    "    q.title as title,\n",
    "    q.id as id,\n",
    "    {},\n",
    "    {}\n",
    " LIMIT 15000          \n",
    "\"\"\".format(start_year, end_year-years_to_use, tspr_str, cites_str)\n",
    "print(query)\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['year','title','id']]\n",
    "for i in range(years_to_use+1):\n",
    "    df_new['c{}'.format(i)] = df.apply(lambda row: row['c{}'.format(row['year']+i)], axis=1)\n",
    "    df_new['p{}'.format(i)] = df.apply(lambda row: row['tspr{}'.format(row['year']+i)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in community features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "feature_paths = [\"/tmp/data/result/FeatureExtractionResults/EarlyAdopters/\"]\n",
    "\n",
    "for feature_path in feature_paths:\n",
    "    all_files = sorted(glob.glob(feature_path +\"*.csv\"), reverse=True)\n",
    "    feature_vec_chunks = []\n",
    "    for file in all_files:\n",
    "        feature_vec_chunks.append(pd.read_csv(file))\n",
    "        \n",
    "    total_feature = pd.concat(feature_vec_chunks)\n",
    "#     print(sorted(total_feature.title))\n",
    "    df_features = df_new.merge(pd.concat(feature_vec_chunks), on='title')\n",
    "\n",
    "# ONLY USES FEATURES WITH FULL SERIES\n",
    "df_features = df_features.dropna()\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            this_xs = this_xs.reindex(np.random.RandomState(seed=42).permutation(this_xs.index))\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = pd.concat(xs)\n",
    "    ys = pd.Series(data=np.concatenate(ys),name='target')\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction + Class Labeling\n",
    "# Train + Test Split\n",
    "## Balanced Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "cs = ['c{}'.format(x) for x in range(years_to_use+1)]\n",
    "ps = ['p{}'.format(x) for x in range(years_to_use+1)]\n",
    "ea = ['early_adopters_{}'.format(x) for x in range(1,years_to_use+1)]\n",
    "cs.extend(ps)\n",
    "cs.extend(ea)\n",
    "X = df_features[cs]\n",
    "y = df_features['p{}'.format(years_to_use)] >= df_features['p{}'.format(years_to_use)].quantile(0.95)\n",
    "\n",
    "\n",
    "to_keep = []\n",
    "num_signals = 1\n",
    "for i in range(years_to_use+1):\n",
    "    \n",
    "    if i == num_signals:\n",
    "        break\n",
    "#     to_keep.append('c{}'.format(i))\n",
    "    to_keep.append('p{}'.format(i))\n",
    "    pass\n",
    "\n",
    "for i in range(1, years_to_use+1):\n",
    "    if i-1 == num_signals:\n",
    "        break\n",
    "#     to_keep.append('early_adopters_{}'.format(i))\n",
    "\n",
    "y = label_binarize(y, classes=[True,False])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "\n",
    "X_restricted = X[to_keep]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_restricted, y, test_size=0.33, random_state=42)\n",
    "X_bal_train, y_bal_train = balanced_subsample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "sensitivity = make_scorer(recall_score, pos_label = 1)\n",
    "specificity = make_scorer(recall_score, pos_label = 0)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'sensitivity': sensitivity,\n",
    "           'specificity': specificity}\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "cv_results = cross_validate(clf, X_bal_train, y_bal_train, scoring=scoring,\n",
    "                         cv=5, return_train_score=True, return_estimator=True)\n",
    "\n",
    "\n",
    "best_est_index = np.argmax(cv_results['test_acc'])\n",
    "best_estimator = cv_results['estimator'][best_est_index]\n",
    "\n",
    "sensitivity(best_estimator, X_test, y_test), specificity(best_estimator, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = best_estimator.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, 1]) # HACK MUST FIX THIS IMMEDIATELY, PROB(CLASS = 1) IS 1ST INDEX IN Y_SCORE\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
