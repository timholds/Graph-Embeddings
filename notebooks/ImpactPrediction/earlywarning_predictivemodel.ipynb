{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://neo4j-allquanta:7687\", auth=('neo4j','myneo'))\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format(\n",
    "    graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "    graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_use = 3\n",
    "start_year = 2003\n",
    "end_year = 2013\n",
    "\n",
    "print(\"Getting dataset...\", end=\" \")\n",
    "cites_str = ',\\n    '.join(['CASE WHEN {} < q.year THEN NULL ELSE SIZE((q)<-[:CITES]-(:Quanta {{year: {}}})) END as c{}'.format(\n",
    "    yr, yr, yr) for yr in range(start_year, end_year+1)])\n",
    "tspr_str = ',\\n    '.join(['q.tspr{} as tspr{}'.format(\n",
    "    yr, yr) for yr in range(start_year, end_year+1)])\n",
    "query = \"\"\"\n",
    "MATCH (q:Quanta)\n",
    "WHERE \n",
    "    (q.doctype='Journal') AND \n",
    "    (q.lang='en') AND \n",
    "    EXISTS(q.fos) AND \n",
    "    (q.year>={} AND q.year <= {}) \n",
    "RETURN\n",
    "    q.year as year,\n",
    "    q.title as title,\n",
    "    q.id as id,\n",
    "    {},\n",
    "    {}\n",
    " LIMIT 15000          \n",
    "\"\"\".format(start_year, end_year-years_to_use, tspr_str, cites_str)\n",
    "print(query)\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['year','title','id']]\n",
    "for i in range(years_to_use+1):\n",
    "    df_new['c{}'.format(i)] = df.apply(lambda row: row['c{}'.format(row['year']+i)], axis=1)\n",
    "    df_new['p{}'.format(i)] = df.apply(lambda row: row['tspr{}'.format(row['year']+i)], axis=1)\n",
    "\n",
    "df_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in community features (don't run!!!)\n",
    "\n",
    "## Issues: inner join on title results in empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "feature_paths = [\"/tmp/data/result/FeatureExtractionResults/EarlyAdopters/\"]\n",
    "\n",
    "for feature_path in feature_paths:\n",
    "    all_files = sorted(glob.glob(feature_path +\"*.csv\"), reverse=True)\n",
    "    feature_vec_chunks = []\n",
    "    for file in all_files:\n",
    "        feature_vec_chunks.append(pd.read_csv(file))\n",
    "        \n",
    "    total_feature = pd.concat(feature_vec_chunks)\n",
    "    \n",
    "    df_new = df_new.merge(pd.concat(feature_vec_chunks), on='title')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "#             np.random.shuffle(this_xs) NOT FOR USE WITH DATAFRAME\n",
    "            this_xs = this_xs.reindex(np.random.permutation(this_xs.index))\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "#     xs = np.concatenate(xs)\n",
    "#     ys = np.concatenate(ys)\n",
    "    xs = pd.concat(xs)\n",
    "    ys = pd.Series(data=np.concatenate(ys),name='target')\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns\n",
    "cs = ['c{}'.format(x) for x in range(years_to_use+1)]\n",
    "ps = ['p{}'.format(x) for x in range(years_to_use+1)]\n",
    "cs.extend(ps)\n",
    "X = df_new[cs]\n",
    "y = df_new['p{}'.format(years_to_use)] >= df_new['p{}'.format(years_to_use)].quantile(0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal, y_bal = balanced_subsample(X,y)\n",
    "y_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df_new['p6'] >= df_new['p6'].quantile(0.90)\n",
    "#X = df_new[['c1','c2','c3']].values\n",
    "#X = df_new[['p1','p2','p3']].values\n",
    "# X = df_new[['p1','p2','p3','c1','c2','c3']].values\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "to_drop = []\n",
    "for i in range(years_to_use+1):\n",
    "#     to_drop.append('c{}'.format(i))\n",
    "#     to_drop.append('p{}'.format(i))\n",
    "    pass\n",
    "\n",
    "\n",
    "    \n",
    "X_bal_processed = X_bal.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = make_scorer(recall_score, pos_label = 1)\n",
    "specificity = make_scorer(recall_score, pos_label = 0)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'sensitivity': sensitivity,\n",
    "           'specificity': specificity}\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "scores = cross_validate(clf, X_bal_processed, y_bal, scoring=scoring,\n",
    "                         cv=5, return_train_score=True)\n",
    "\n",
    "print(scores['test_acc'].mean())\n",
    "print(scores['test_sensitivity'].mean())\n",
    "print(scores['test_specificity'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
