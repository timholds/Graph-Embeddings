{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, math\n",
    "!pip install tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from py2neo import Graph, Node, Relationship\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph('bolt://neo4j-allquanta:7687', auth=('neo4j','myneo'))\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, end_year, step = 2000, 2018, 1\n",
    "min_year_year = 1950\n",
    "\n",
    "def run_query(query, graph, print_query=False, run_query=True, \n",
    "              print_only=False, to_df=False):\n",
    "    df = 1\n",
    "    if print_only: \n",
    "        print_query = True\n",
    "        run_query = False\n",
    "    start_time = time.time()\n",
    "    if print_query:\n",
    "        print(query)\n",
    "    if run_query:\n",
    "        if to_df:\n",
    "            df = graph.run(query).to_data_frame()\n",
    "        else:\n",
    "            graph.run(query)\n",
    "    end_time = time.time()\n",
    "    minutes_elapsed = (end_time-start_time)/60\n",
    "    print(\"Query completed in {:.2f} minutes.\".format(minutes_elapsed))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect data for given area of interest\n",
    "# time-scaled PageRank by all Nature authors from start_year to end_year\n",
    "\n",
    "tspr_sums = ',\\n    '.join(['SUM(q.tsprn{}) as tsprn{}'.format(i,i) for i in range(start_year, end_year+1)])\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:NatureAuthor)-[:AUTHORED]->(p:Quanta)\n",
    "WHERE (p.year > {} AND p.year < {}) AND (p.venue=\"Nature\") \n",
    "\n",
    "AND (\"Malaria\" in p.fos OR \"MALARIA\" in p.fos OR \"malaria\" in p.fos OR\n",
    "     \"malaria\" in p.keywords OR \"MALARIA\" in p.keywords)\n",
    "     \n",
    "WITH *, collect(a) as alist\n",
    "MATCH (b)-[:AUTHORED]->(q:Quanta {{venue:\"Nature\"}})\n",
    "WHERE b IN alist\n",
    "RETURN \n",
    "    a.name as name, \n",
    "    {}\n",
    "\"\"\".format(start_year-1, end_year+1, tspr_sums)\n",
    "df = run_query(query, graph, to_df=True, print_only=True)\n",
    "old_df = df\n",
    "print(\"Found {:,} authors.\".format(len(df.index)))\n",
    "\n",
    "# AND (\"CRISPR\" in p.fos OR \"Cas9\" in p.fos OR \"Crispr\" in p.fos OR\n",
    "#      \"crispr\" in p.keywords OR \"cas9\" in p.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean and format data\n",
    "\n",
    "# Convert to time series matrix\n",
    "df = old_df.T\n",
    "df.columns = df.loc['name'].tolist()\n",
    "df = df.drop(index='name')\n",
    "\n",
    "# Drop columns with zeros\n",
    "# names_to_drop = df.columns[(df==0).any()]\n",
    "# df = df.drop(columns=names_to_drop)\n",
    "df = df.clip(lower=1e-4)\n",
    "n_authors = df.shape[1]\n",
    "print(\"Now have {:,} authors.\".format(n_authors))\n",
    "\n",
    "# Convert rows to Datetime\n",
    "df.index = pd.to_datetime(['01/01/{}'.format(s[-4:]) for s in df.index],\n",
    "               infer_datetime_format=True)\n",
    "\n",
    "# Convert all data to float type\n",
    "df = df.astype(float)\n",
    "\n",
    "# Calculate log returns\n",
    "log_ret = np.log(df/df.shift(1))\n",
    "log_ret = log_ret.iloc[1:,]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte Carlo Simulation \n",
    "\n",
    "n_grants = 200000\n",
    "n_authors_per_grant = 4\n",
    "\n",
    "np.random.seed(42)\n",
    "all_weights = np.zeros((n_grants, n_authors_per_grant))\n",
    "all_authors = []\n",
    "ret_arr = np.zeros(n_grants)\n",
    "vol_arr = np.zeros(n_grants)\n",
    "sharpe_arr = np.zeros(n_grants)\n",
    "\n",
    "for x in tqdm(range(n_grants)):\n",
    "    \n",
    "    # Select assets (authors)\n",
    "    authors = random.sample(list(df.columns), k=n_authors_per_grant)\n",
    "    all_authors.append(authors)\n",
    "    returns = log_ret.loc[:,authors]\n",
    "    \n",
    "    # Random weights\n",
    "    weights = np.array(np.random.random(n_authors_per_grant))\n",
    "    weights = weights/np.sum(weights)\n",
    "    all_weights[x,:] = weights\n",
    "    \n",
    "    # Expected return\n",
    "    ret_arr[x] = np.sum( (returns.mean() * weights))\n",
    "    \n",
    "    # Expected volatility\n",
    "    vol_arr[x] = np.sqrt(np.dot(weights.T, np.dot(returns.cov(), weights)))\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_arr[x] = ret_arr[x]/vol_arr[x]\n",
    "\n",
    "\n",
    "max_sr_ret = ret_arr[sharpe_arr.argmax()]\n",
    "max_sr_vol = vol_arr[sharpe_arr.argmax()]\n",
    "print(\"Maximum Sharpe ratio: {}\".format(sharpe_arr.max()))\n",
    "print(\"\\tLocation in array: {}\".format(sharpe_arr.argmax()))\n",
    "print(\"\\tImpact: {}\".format(max_sr_ret))\n",
    "print(\"\\tRisk: {}\".format(max_sr_vol))\n",
    "print(\"\\tResearchers: \\n\\t\\t{}\".format(',\\n\\t\\t'.join(all_authors[sharpe_arr.argmax()])))\n",
    "print(\"\\tWeighting: {}\".format(all_weights[sharpe_arr.argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, s=10, cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Impact')\n",
    "plt.scatter(max_sr_vol, max_sr_ret,c='red', s=100) # red dot\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solve for best grant\n",
    "def get_ret_vol_sr(weights):\n",
    "    weights = np.array(weights)\n",
    "    ret = np.sum(log_ret.mean() * weights) * 252\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov()*252, weights)))\n",
    "    sr = ret/vol\n",
    "    return np.array([ret, vol, sr])\n",
    "\n",
    "def neg_sharpe(weights):\n",
    "# the number 2 is the sharpe ratio index from the get_ret_vol_sr\n",
    "    return get_ret_vol_sr(weights)[2] * -1\n",
    "\n",
    "def check_sum(weights):\n",
    "    #return 0 if sum of the weights is 1\n",
    "    return np.sum(weights)-1\n",
    "\n",
    "def minimize_volatility(weights):\n",
    "    return get_ret_vol_sr(weights)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "cons = ({'type':'eq', 'fun':check_sum})\n",
    "bounds = ((0,1),)*log_ret.shape[1]\n",
    "init_guess = [1/log_ret.shape[1]]*log_ret.shape[1]\n",
    "\n",
    "opt_results = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "old_df['name'][opt_results.x>1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ret_vol_sr(opt_results.x)\n",
    "frontier_y = np.linspace(0,ret_arr.max()+1,10)\n",
    "\n",
    "frontier_x = []\n",
    "\n",
    "for possible_return in tqdm(frontier_y):\n",
    "    cons = ({'type':'eq', 'fun':check_sum},\n",
    "            {'type':'eq', 'fun': lambda w: get_ret_vol_sr(w)[0] - possible_return})\n",
    "    \n",
    "    result = minimize(minimize_volatility,init_guess,method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    frontier_x.append(result['fun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Return')\n",
    "plt.plot(frontier_x,frontier_y, 'r--', linewidth=3)\n",
    "plt.savefig('cover.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
