{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship \n",
    "\n",
    "#graph = Graph(\"http://matlaber5.media.mit.edu:1234\", auth=('neo4j', 'password'))\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "#n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "#print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     #(n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"MATCH (b) RETURN b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run STREAMING PageRank (1) on each year from 1800 to 2020\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "start_year, end_year, step = 1985, 2010, 5\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1, step):\n",
    "    \n",
    "    # < IS MUCH FASTER THAN <=\n",
    "    print(\"Running PageRank on works from < {}...\".format(year), end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank.stream(\n",
    "    'MATCH (p:Quanta) WHERE p.year < {} RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', iterations:20, write:false, concurrency:20}})\n",
    "    YIELD node, score\n",
    "    WITH \n",
    "        *,\n",
    "        node.id AS id, \n",
    "        node.title AS title, \n",
    "        node.lang AS lang, \n",
    "        node.year AS year, \n",
    "        node.keywords AS keywords, \n",
    "        node.fos AS fos, \n",
    "        node.publisher AS publisher,\n",
    "        score AS page_rank\n",
    "    ORDER BY page_rank DESC\n",
    "    LIMIT 10000\n",
    "    RETURN \n",
    "        id,\n",
    "        title,\n",
    "        lang, \n",
    "        year, \n",
    "        keywords, \n",
    "        fos, \n",
    "        publisher,\n",
    "        page_rank;    \n",
    "    \"\"\".format(year,year,year)\n",
    "    \n",
    "    #graph.run(query)\n",
    "\n",
    "    print(query)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "    print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))\n",
    "    \n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((time.time()-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(dfs)\n",
    "all_results_path = '/tmp/data/result/allResults_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing all results to {}...\".format(all_results_path), end=\" \")\n",
    "all_results.to_csv(path_or_buf=all_results_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# all_results['title_clean'] = all_results['title'].str.replace(',',' ')\n",
    "all_results['primary_field'] = all_results['fos'].apply(lambda x: x[0] if np.all(pd.notnull(x)) else None)\n",
    "result = all_results.pivot_table(index=['title','primary_field','publisher'], columns='year', values='impact')    \n",
    "\n",
    "file_path = '/tmp/data/result/impact_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graph loading (notes; do not execute)\n",
    "# # // Load graph\n",
    "CALL algo.graph.load('my-graph','Label','REL_TYPE',{graph:'heavy',..other config...})\n",
    "  YIELD name, graph, direction, undirected, sorted, nodes, loadMillis, alreadyLoaded,\n",
    "        nodeWeight, relationshipWeight, nodeProperty, loadNodes, loadRelationships;\n",
    "\n",
    "# # // Info on loaded graph\n",
    "# CALL algo.graph.info('my-graph')\n",
    "#   YIELD name, type, exists, removed, nodes;\n",
    "\n",
    "# # // Use graph\n",
    "# CALL algo.pageRank(null,null,{graph:'my-graph',...})\n",
    "\n",
    "\n",
    "# # // Remove graph\n",
    "# CALL algo.graph.remove('my-graph')\n",
    "#   YIELD name, type, exists, removed, nodes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
