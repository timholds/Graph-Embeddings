{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Calculate the top 1,000 {patents, papers} {overall, by individual year} by {PageRank, ArticleRank, time-scaled PageRank, time-scaled ArticleRank}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\", auth=('neo4j','myneo'))\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write PageRank and ArticleRank to the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write PageRank and ArticleRank, run on entire graph, to each node\n",
    "for alg in ['articleRank', 'pageRank']:\n",
    "    query = \"\"\"\n",
    "    CALL algo.{}(\n",
    "        'MATCH (p:Quanta) RETURN id(p) as id',\n",
    "        'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "        {{graph:'cypher', iterations:35, write:true, writeProperty:'{}'}});\n",
    "    \"\"\".format(alg, alg.lower())\n",
    "#     print(query)\n",
    "    query_start_time = time.time()\n",
    "    graph.run(query)\n",
    "    print(\"Wrote {} to full graph in {:.2f} minutes.\".format(alg.capitalize(), (time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate top quanta overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top overall quanta by citations\n",
    "\n",
    "filepath = '/import/result/top_quanta_overall_citations.csv'\n",
    "\n",
    "query = \"\"\"\n",
    "CALL apoc.export.csv.query(\"MATCH (q:Quanta)\n",
    "WHERE \n",
    "    q.title IS NOT NULL AND \n",
    "    q.title <> \\\\\"\\\\\" AND \n",
    "    q.venue=\\\\\"Nature\\\\\" AND q.year>2010\n",
    "WITH \n",
    "    q.title as title, \n",
    "    q.year as year,\n",
    "    q.id as id, \n",
    "    q.n_citation as google_citations, \n",
    "    SIZE((q)<-[:CITES]-(:Quanta)) as graph_citations\n",
    "WHERE graph_citations > 0\n",
    "WITH *, MAX(google_citations, graph_citations) as max_citations\n",
    "ORDER BY max_citations DESC\n",
    "RETURN title, id, year, graph_citations, google_citations, max_citations\n",
    "\",\"{}\", {{}})\n",
    "\"\"\".format(filepath)\n",
    "\n",
    "# print(query)\n",
    "query_start_time = time.time()\n",
    "graph.run(query)\n",
    "print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By PageRank and ArticleRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top overall quanta by PageRank and ArticleRank\n",
    "for alg in ['pageRank', 'articleRank']:\n",
    "    \n",
    "    filepath = '/import/result/top_quanta_overall_{}.csv'.format(alg.lower())\n",
    "\n",
    "    query = \"\"\"\n",
    "    CALL apoc.export.csv.query(\"MATCH (q:Quanta)\n",
    "    WHERE \n",
    "        q.title IS NOT NULL AND \n",
    "        q.title <> \\\\\"\\\\\" AND \n",
    "        q.venue=\\\\\"Nature\\\\\" AND q.year>2010\n",
    "    WITH \n",
    "        q.title as title, \n",
    "        q.year as year,\n",
    "        q.id as id, \n",
    "        q.pagerank as pagerank, \n",
    "        q.articlerank as articlerank\n",
    "    ORDER BY {} DESC\n",
    "    RETURN title, id, year, pagerank, articlerank\n",
    "    \",\"{}\", {{}})\n",
    "    \"\"\".format(alg.lower(), filepath)\n",
    "\n",
    "    print(query)\n",
    "    \n",
    "    query_start_time = time.time()\n",
    "#     graph.run(query)\n",
    "    print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By time-scaled PageRank and time-scaled ArticleRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top overall quanta by TIME SCALED PageRank and ArticleRank\n",
    "for alg in ['pageRank', 'articleRank']:\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Quanta)\n",
    "    WHERE p.title IS NOT NULL AND p.title <> \"\" AND (size(p.authors)>0)\n",
    "    WITH \n",
    "        *,  \n",
    "        p.id AS id, \n",
    "        p.title AS title,\n",
    "        p.year AS year, \n",
    "        p.pagerank AS pagerank\n",
    "    ORDER BY pagerank DESC\n",
    "    WITH year, COLLECT({{title: title,  page_rank: pagerank}})[..1000] AS data, AVG(pagerank) AS avg_page_rank, stDev(pagerank) as stdDev\n",
    "    UNWIND data AS d\n",
    "    RETURN  \n",
    "        d.id AS id,\n",
    "        d.title AS title, \n",
    "        d.year AS year, \n",
    "        ABS(d.pagerank-avg_page_rank)/stdDev AS scaled_score;\n",
    "    \"\"\".format(year,year,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Patents by PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top patents by PageRank\n",
    "query = \"\"\"\n",
    "MATCH (p:Patent)\n",
    "WHERE p.title IS NOT NULL AND p.title <> \"\" AND (size(p.authors)>0)\n",
    "WITH \n",
    "    p.title as title, \n",
    "    p.year as year,\n",
    "    p.id as id, \n",
    "    p.authors as authors, \n",
    "    p.n_citation as google_citations,\n",
    "    p.pagerank as pagerank\n",
    "ORDER BY pagerank DESC\n",
    "RETURN title, id, year, authors, google_citations, pagerank\n",
    "LIMIT 100000\n",
    "\"\"\"\n",
    "query_start_time = time.time()\n",
    "# df = graph.run(query).to_data_frame()\n",
    "print(query)\n",
    "print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='title', inplace=True)\n",
    "df.drop_duplicates(subset='id', inplace=True)\n",
    "df['authors'] = df['authors'].apply(lambda x: ', '.join(x))\n",
    "df.columns = ['Authors', 'Citations_GooglePatents', 'ID', 'PageRank', 'Title', 'Year']\n",
    "df.to_csv(path_or_buf='/tmp/data/result/patents_by_pagerank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years = df.copy()\n",
    "df_years.drop_duplicates(subset='Year', inplace=True)\n",
    "df_years = df_years.sort_values(by='Year', ascending=False)\n",
    "df_years.to_csv(path_or_buf='/tmp/data/result/top_yearly_patent_by_pagerank.csv')\n",
    "df_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top inventors by PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Author)-[:AUTHORED]->(p:Patent)\n",
    "WHERE \n",
    "    (a.name <> \"\") AND \n",
    "    (a.name IS NOT NULL) \n",
    "    (size(split(a.name, ' ')) > 1) AND \n",
    "    (p.title IS NOT NULL) AND \n",
    "    (p.title <> \"\") AND \n",
    "    (size(p.authors)>0)\n",
    "WITH \n",
    "  a.name AS name, \n",
    "  COUNT(p) AS num_patents,\n",
    "  SUM(p.n_citation) AS sum_citations, \n",
    "  SUM(p.pagerank) AS sum_pagerank\n",
    "ORDER BY sum_pagerank DESC\n",
    "LIMIT 2000\n",
    "RETURN *\n",
    "\"\"\"\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(subset='name', inplace=True)\n",
    "df.columns = ['Name', 'Num_Patents', 'Sum_Citations', 'Sum_PageRank']\n",
    "df.to_csv(path_or_buf='/tmp/data/result/inventors_by_pagerank.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top patents by ArticleRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top patents by ArticleRank\n",
    "query = \"\"\"\n",
    "CALL algo.articleRank.stream(\n",
    "  'MATCH (p:Patent) RETURN id(p) as id',\n",
    "  'MATCH (p1:Patent)-[:CITES]->(p2:Patent) RETURN id(p1) as source, id(p2) as target',\n",
    "  {graph:'cypher'}\n",
    ") YIELD node, score \n",
    "WITH\n",
    "    node as p,\n",
    "    score\n",
    "ORDER BY score DESC\n",
    "LIMIT 10000\n",
    "RETURN \n",
    "    p.title as Title, \n",
    "    p.authors as Authors,\n",
    "    p.id as ID,\n",
    "    p.year as Year,\n",
    "    p.n_citation as Citations_GooglePatents,\n",
    "    score as PageRank\n",
    "\"\"\"\n",
    "\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "# print(query)\n",
    "print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='Title', inplace=True)\n",
    "df.drop_duplicates(subset='ID', inplace=True)\n",
    "df['Authors'] = df['Authors'].apply(lambda x: ', '.join(x))\n",
    "df.columns = ['Authors', 'n_citations', 'ID', 'ArticleRank', 'Title', 'Year']\n",
    "df.to_csv(path_or_buf='/tmp/data/top_patent_by_articlerank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top inventors by citation count TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top inventors by Citations\n",
    "query = \"\"\"\n",
    "MATCH (a:Author)-[:AUTHORED]->(p:Patent)\n",
    "WHERE \n",
    "    (a.name <> \"\") AND \n",
    "    (a.name IS NOT NULL) AND \n",
    "    (size(split(a.name, ' ')) > 1) AND \n",
    "    (p.title IS NOT NULL) \n",
    "    AND (p.title <> \"\") AND \n",
    "    (size(p.authors)>0)\n",
    "WITH \n",
    "  a.name AS name, \n",
    "  COUNT(p) AS num_patents,\n",
    "  SUM(p.n_citation) AS sum_citations, \n",
    "  SUM(p.pagerank) AS sum_pagerank\n",
    "ORDER BY sum_pagerank DESC\n",
    "LIMIT 1000\n",
    "RETURN *\n",
    "\"\"\"\n",
    "query_start_time = time.time()\n",
    "df = graph.run(query).to_data_frame()\n",
    "print(\"Done query in {:.2f} minutes.\".format((time.time()-query_start_time)/60))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top Papers by Time-Scaled PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Scaled PageRank that returns top 1000 papers per year\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "\n",
    "# Run STREAMING PageRank (1) on each year from 1800 to 2020\n",
    "start_time = time.time()\n",
    "start_year, end_year, step = 1985, 2010, 5\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1, step):\n",
    "    \n",
    "    # < IS MUCH FASTER THAN <=\n",
    "    print(\"Running PageRank on works from < {}...\".format(year), end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank.stream(\n",
    "    'MATCH (p:Quanta) WHERE p.year < 2015 RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', iterations:20, write:false, concurrency:20}})\n",
    "    YIELD node, score\n",
    "    WITH \n",
    "        *,  \n",
    "        node.id AS id, \n",
    "        node.title AS title,\n",
    "        node.lang AS lang, \n",
    "        node.year AS year, \n",
    "        node.keywords AS keywords, \n",
    "        node.fos AS fos, \n",
    "        node.publisher AS publisher,\n",
    "        score AS pagerank\n",
    "    ORDER BY pagerank DESC\n",
    "    WITH year, COLLECT({{title: title,  page_rank: pagerank}})[..1000] AS data, AVG(pagerank) AS avg_page_rank, stDev(pagerank) as stdDev\n",
    "    UNWIND data AS d\n",
    "    RETURN d.year as year, \n",
    "        d.id AS id,\n",
    "        d.title AS title, \n",
    "        d.lang AS lang, \n",
    "        d.keywords as keywords, \n",
    "        d.publisher as fos, \n",
    "        d.publisher as publisher,\n",
    "        ABS(d.pagerank-avg_page_rank)/stdDev AS scaled_score;\n",
    "    \"\"\".format(year,year,year)\n",
    "    \n",
    "    #graph.run(query)\n",
    "    #print(query)\n",
    "    \n",
    "    df = graph.run(query).to_data_frame()\n",
    "    \n",
    "    \n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((time.time()-start_time)/60))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
