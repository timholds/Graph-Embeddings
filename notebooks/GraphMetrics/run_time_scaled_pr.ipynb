{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Scaled PageRank\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "query_start_time = time.time()\n",
    "query = \"\"\"\n",
    "MATCH (p:Patent)\n",
    "WHERE p.title IS NOT NULL AND p.title <> \"\" AND (size(p.authors)>0)\n",
    "WITH \n",
    "    *,  \n",
    "    p.id AS id, \n",
    "    p.title AS title,\n",
    "    p.year AS year, \n",
    "    p.pagerank AS pagerank\n",
    "ORDER BY pagerank DESC\n",
    "WITH year, COLLECT({{title: title,  page_rank: pagerank}})[..1000] AS data, AVG(pagerank) AS avg_page_rank, stDev(pagerank) as stdDev\n",
    "UNWIND data AS d\n",
    "RETURN  \n",
    "    d.id AS id,\n",
    "    d.title AS title, \n",
    "    d.year AS year, \n",
    "    ABS(d.pagerank-avg_page_rank)/stdDev AS scaled_score;\n",
    "\"\"\".format(year,year,year)\n",
    "\n",
    "print(query)\n",
    "df = graph.run(query).to_data_frame()\n",
    "    \n",
    "    \n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((time.time()-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='title', inplace=True)\n",
    "df.drop_duplicates(subset='id', inplace=True)\n",
    "# df['authors'] = df['authors'].apply(lambda x: ', '.join(x))\n",
    "df.to_csv(path_or_buf='/tmp/data/patents_by_tspagerank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run STREAMING PageRank (1) on each year from 1800 to 2020\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "start_year, end_year, step = 1985, 2010, 5\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1, step):\n",
    "    \n",
    "    # < IS MUCH FASTER THAN <=\n",
    "    print(\"Running PageRank on works from < {}...\".format(year), end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank.stream(\n",
    "    'MATCH (p:Quanta) WHERE p.year < {} RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', iterations:20, write:false, concurrency:20}})\n",
    "    YIELD node, score\n",
    "    WITH \n",
    "        *,\n",
    "        node.id AS id, \n",
    "        node.title AS title, \n",
    "        node.lang AS lang, \n",
    "        node.year AS year, \n",
    "        node.keywords AS keywords, \n",
    "        node.fos AS fos, \n",
    "        node.publisher AS publisher,\n",
    "        score AS page_rank\n",
    "    ORDER BY page_rank DESC\n",
    "    LIMIT 10000\n",
    "    RETURN \n",
    "        id,\n",
    "        title,\n",
    "        lang, \n",
    "        year, \n",
    "        keywords, \n",
    "        fos, \n",
    "        publisher,\n",
    "        page_rank;    \n",
    "    \"\"\".format(year,year,year)\n",
    "    \n",
    "    #graph.run(query)\n",
    "\n",
    "    #print(query)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    #df['year'] = year\n",
    "    #dfs.append(df)\n",
    "    #print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))\n",
    "    \n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't scale things within the query and just run regular pagerank, we can use this to do time-scaled-pr\n",
    "def normalize_and_sort(df):\n",
    "    df['scores_minus_mean'] = df.groupby('year').score - df.groupby('year').score.mean()\n",
    "    df['scaled_scores'] = df.groupby('year').score_minus_mean / df.groupby('year').score.std()\n",
    "    df = df.sort_values(['scaled_scores'], ascending=False).head(1000)\n",
    "    \n",
    "    #df['scores_minus_mean'] = df['score'] - mean\n",
    "    #df['scaled_scores'] = df['scores_minus_mean'].divide(stDev, axis=1)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 1,000 scaled scores\n",
    "results = normalize_and_sort(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(dfs)\n",
    "all_results_path = '/tmp/data/result/allResults_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing all results to {}...\".format(all_results_path), end=\" \")\n",
    "all_results.to_csv(path_or_buf=all_results_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# all_results['title_clean'] = all_results['title'].str.replace(',',' ')\n",
    "all_results['primary_field'] = all_results['fos'].apply(lambda x: x[0] if np.all(pd.notnull(x)) else None)\n",
    "result = all_results.pivot_table(index=['title','primary_field','publisher'], columns='year', values='impact')    \n",
    "\n",
    "file_path = '/tmp/data/result/impact_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra stuff \n",
    "\n",
    "# Make fake data\n",
    "a = {'scores': [1, 2, 4, 18, 25, 13]}\n",
    "df1950 = pd.DataFrame(data=a)\n",
    "b = {'scores': [2, 7, 4, 68, 20, 13]}\n",
    "df1951 = pd.DataFrame(data=b)\n",
    "c = {'scores': [9, 8, 4, 18, 5, 83]}\n",
    "df1952 = pd.DataFrame(data=c)\n",
    "\n",
    "# Normalize each dataframe which represents pagerank scores of papers published in a given year\n",
    "d1 = normalize_scores_for_year(df1950)\n",
    "d2 = normalize_scores_for_year(df1951)\n",
    "d3 = normalize_scores_for_year(df1952)\n",
    "\n",
    "years = [d1, d2, d3]\n",
    "#years = ['df_' + year for year in range(1900, 2000)]\n",
    "\n",
    "# Find the top papers from all the years combined and return the top 1000\n",
    "all_years_df = combine_scores(years)\n",
    "result = get_top_papers(all_years_df)\n",
    "    \n",
    "print(result)\n",
    "\n",
    "def normalize_scores_for_year_df(df):\n",
    "    \n",
    "    mean = df['scores'].mean(axis=0)\n",
    "    std =  df['scores'].std(axis=0)\n",
    "    #print(mean)\n",
    "    #print(std)\n",
    "\n",
    "    scores_minus_mean = df - mean\n",
    "    scaled_scores = scores_minus_mean.divide(std, axis=1)\n",
    "\n",
    "    #print(df)\n",
    "    #print(scaled_scores)\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled_scores)\n",
    "    sorted_df = scaled_df.sort_values(['scores'], ascending=False).head(1000)\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "def combine_scores(dfs):\n",
    "    all_years_df = pd.concat(dfs)\n",
    "    return all_years_df\n",
    "\n",
    "#d = {'paper': ['A', 'BB', 'C', 'd', 'E', 'f'], 'scores': [1, 2, 4, 18, 25, 13]}\n",
    "d = {'scores': [1, 2, 4, 18, 25, 13]}\n",
    "#data2 = [{'scores': scores}]#, {'a': 5, 'b': 10, 'c': 20}, {'a': 0, 'b': 8, 'c': 30}]\n",
    "df = pd.DataFrame(data=d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
