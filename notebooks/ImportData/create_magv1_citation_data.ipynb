{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dict from magv1 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/data/magone/mag_papers_0.txt\n",
      "Added papers from file to dict in 28.02 seconds.\n",
      "Total of 1000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_1.txt\n",
      "Added papers from file to dict in 29.06 seconds.\n",
      "Total of 2000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_2.txt\n",
      "Added papers from file to dict in 28.58 seconds.\n",
      "Total of 3000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_3.txt\n",
      "Added papers from file to dict in 28.27 seconds.\n",
      "Total of 4000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_4.txt\n",
      "Added papers from file to dict in 28.55 seconds.\n",
      "Total of 5000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_5.txt\n",
      "Added papers from file to dict in 28.69 seconds.\n",
      "Total of 6000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_6.txt\n",
      "Added papers from file to dict in 28.16 seconds.\n",
      "Total of 7000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_7.txt\n",
      "Added papers from file to dict in 27.46 seconds.\n",
      "Total of 8000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_8.txt\n",
      "Added papers from file to dict in 28.93 seconds.\n",
      "Total of 9000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_9.txt\n",
      "Added papers from file to dict in 27.81 seconds.\n",
      "Total of 10000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_10.txt\n",
      "Added papers from file to dict in 27.59 seconds.\n",
      "Total of 11000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_11.txt\n",
      "Added papers from file to dict in 29.82 seconds.\n",
      "Total of 12000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_12.txt\n",
      "Added papers from file to dict in 28.75 seconds.\n",
      "Total of 13000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_13.txt\n",
      "Added papers from file to dict in 27.84 seconds.\n",
      "Total of 14000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_14.txt\n",
      "Added papers from file to dict in 28.88 seconds.\n",
      "Total of 15000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_15.txt\n",
      "Added papers from file to dict in 28.61 seconds.\n",
      "Total of 16000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_16.txt\n",
      "Added papers from file to dict in 29.04 seconds.\n",
      "Total of 17000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_17.txt\n",
      "Added papers from file to dict in 25.99 seconds.\n",
      "Total of 18000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_18.txt\n",
      "Added papers from file to dict in 24.84 seconds.\n",
      "Total of 19000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_19.txt\n",
      "Added papers from file to dict in 25.04 seconds.\n",
      "Total of 20000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_20.txt\n",
      "Added papers from file to dict in 24.39 seconds.\n",
      "Total of 21000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_21.txt\n",
      "Added papers from file to dict in 26.60 seconds.\n",
      "Total of 22000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_22.txt\n",
      "Added papers from file to dict in 26.33 seconds.\n",
      "Total of 23000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_23.txt\n",
      "Added papers from file to dict in 25.10 seconds.\n",
      "Total of 24000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_24.txt\n",
      "Added papers from file to dict in 25.58 seconds.\n",
      "Total of 25000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_25.txt\n",
      "Added papers from file to dict in 26.66 seconds.\n",
      "Total of 26000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_26.txt\n",
      "Added papers from file to dict in 24.68 seconds.\n",
      "Total of 27000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_27.txt\n",
      "Added papers from file to dict in 24.45 seconds.\n",
      "Total of 28000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_28.txt\n",
      "Added papers from file to dict in 24.52 seconds.\n",
      "Total of 29000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_29.txt\n",
      "Added papers from file to dict in 24.14 seconds.\n",
      "Total of 30000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_30.txt\n",
      "Added papers from file to dict in 24.67 seconds.\n",
      "Total of 31000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_31.txt\n",
      "Added papers from file to dict in 24.01 seconds.\n",
      "Total of 32000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_32.txt\n",
      "Added papers from file to dict in 24.05 seconds.\n",
      "Total of 33000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_33.txt\n",
      "Added papers from file to dict in 25.50 seconds.\n",
      "Total of 34000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_34.txt\n",
      "Added papers from file to dict in 24.27 seconds.\n",
      "Total of 35000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_35.txt\n",
      "Added papers from file to dict in 24.80 seconds.\n",
      "Total of 36000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_36.txt\n",
      "Added papers from file to dict in 24.89 seconds.\n",
      "Total of 37000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_37.txt\n",
      "Added papers from file to dict in 25.14 seconds.\n",
      "Total of 38000000 lines in the dictionary after running\n",
      "/tmp/data/magone/mag_papers_38.txt\n"
     ]
    }
   ],
   "source": [
    "# Make ID-title dict from magv1 papers \n",
    "def json_to_dict(files):\n",
    "    id_dict = dict()\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        start_time = time.time()\n",
    "\n",
    "        with open(file) as f:\n",
    "            data = f.readlines()\n",
    "            for line in data:\n",
    "                jsondata = json.loads(line)\n",
    "                paper_id = jsondata['id']\n",
    "                title = jsondata['title']\n",
    "                id_dict.update({paper_id : title})\n",
    "                end_time = time.time()\n",
    "\n",
    "        seconds_elapsed = (end_time-start_time)\n",
    "        print(\"Added papers from file to dict in {:.2f} seconds.\".format(seconds_elapsed))\n",
    "        print(\"Total of \" + str(len(id_dict)) + \" lines in the dictionary after running\")\n",
    "    \n",
    "    return id_dict\n",
    "\n",
    "id_dict = json_to_dict(files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/skokada/data/magone/mag_papers_0_clean.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/u/skokada/data/magone/mag_papers_0_clean.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dafb7deb0c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u/skokada/data/magone/mag_papers_0_clean.txt'"
     ]
    }
   ],
   "source": [
    "# Replace the ids with the titles and write the file back\n",
    "\n",
    "data_dir = '/tmp/data/magone/'\n",
    "files = [data_dir + 'mag_papers_{}.txt'.format(i) for i in range(167)]\n",
    "\n",
    "n_key_errors = 0\n",
    "n_no_citations = 0\n",
    "file_num = 0\n",
    "\n",
    "for file in files:\n",
    "    file_out = data_dir + 'mag_papers_{}_clean.txt'.format(file_num)\n",
    "    n_file_key_errors = 0\n",
    "    n_file_no_citations = 0\n",
    "    \n",
    "    print(\"Creating {}...\".format(file_out))\n",
    "    with open (file) as f:\n",
    "        with open(file_out, 'w') as f1:\n",
    "            data = f.readlines()\n",
    "            for line in data:\n",
    "                jsondata = json.loads(line)\n",
    "                new_line = line\n",
    "                if 'references' in jsondata.keys():\n",
    "                    ref_ids = jsondata['references']\n",
    "                    for ref_id in ref_ids:\n",
    "                        try:\n",
    "                            title = json.dumps(id_dict[ref_id])\n",
    "                            new_line = str.replace(new_line, ref_id, title)\n",
    "                        except KeyError:\n",
    "                            n_file_key_errors += 1\n",
    "                else: # this paper doesn't cite any other papers\n",
    "                    n_file_no_citations += 1\n",
    "                f1.write(new_line)\n",
    "                \n",
    "    print(\"\\tKey Errors: {}\".format(n_file_key_errors))\n",
    "    print(\"\\tNo Citations: {}\".format(n_file_no_citations))    \n",
    "                \n",
    "    n_key_errors += n_file_key_errors\n",
    "    n_no_citations += n_file_no_citations\n",
    "    \n",
    "    file_num = int(file_num_str)\n",
    "    file_num += 1 \n",
    "\n",
    "print(\"\\nDONE!\\nTotal Key Errors: {}\".format(n_file_key_errors))\n",
    "print(\"Total No Citations: {}\".format(n_file_no_citations))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_filename = ':memory:'\n",
    "#db_filename = 'example.db'\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''DROP TABLE mag''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "c.execute('''CREATE TABLE mag\n",
    "         (id varchar(15), title text, refs text)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For importing everything a df and read the lines\n",
    "# TODO Update this to an optimized df\n",
    "files = ['/Users/timholdsworth/code/scaling-science/notebooks/data/v1/mag_1e3.txt']\n",
    "big_frame = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = dd.read_json(file, lines=True)\n",
    "    #big_frame = big_frame.append(df, ignore_index=True)\n",
    "    df_big = dd.concat([df], axis=1)\n",
    "    \n",
    "\n",
    "df = pd.read_json(file, lines=True)\n",
    "\n",
    "\n",
    "for row in df.iterrows():\n",
    "    print(row[1]['references'])\n",
    "    #c.execute(\"insert into mag values (?, ?)\", [str(row[1]['id']), row[1]['title']])\n",
    "    try:\n",
    "        c.execute(\"insert into mag values (?, ?, ?)\", [row[1]['id'], row[1]['title'], row[1]['references']])\n",
    "    except:\n",
    "        print(\"Interface error, probably NaN value\")\n",
    "        \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Close db connection\n",
    "# 36 characters long for id field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('SELECT * FROM mag')\n",
    "all_rows = c.fetchall()\n",
    "all_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the MAGv1 with titles in references using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from numpy import nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For importing everything into one big dataframe\n",
    "start_time = time.time()\n",
    "paper_files = ['/Users/timholdsworth/code/scaling-science/notebooks/data/v1/mag_papers_8/mag_papers_100k_165.txt']\n",
    "big_frame = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = dd.read_json(file, lines=True)\n",
    "    #big_frame = big_frame.append(df, ignore_index=True)\n",
    "    df_big = dd.concat([df], axis=1)\n",
    "    \n",
    "\n",
    "df = pd.read_json(file, lines=True)\n",
    "\n",
    "end_time = time.time()\n",
    "seconds_elapsed = end_time-start_time\n",
    "print(\"Query completed in {:.2f} seconds.\".format(seconds_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = \"/Users/timholdsworth/code/scaling-science/notebooks/data/v1/mag_papers_clean_0.txt\"\n",
    "start_time = time.time()\n",
    "with open(file_out, \"w+\") as f:\n",
    "    for row in df.iterrows(): \n",
    "        paper_id = row[1][5]\n",
    "        title = row[1][14] \n",
    "        refs_list = row[1][13] \n",
    "                \n",
    "        if type(refs_list) is float: # there are no citations\n",
    "            #print('no citations')\n",
    "            f.write(str({\"id\": paper_id, \"title\": title}))\n",
    "        \n",
    "        else: # there are citations\n",
    "            #print('existing citations, matching id to title')\n",
    "            refs_titled = []\n",
    "            for ref in refs_list:\n",
    "\n",
    "                # Once/if all the ids are in the database we can take this if else out\n",
    "                if df[df['id'] == ref].empty: # the id doesn't match for paper in the df\n",
    "                    pass\n",
    "                else:\n",
    "                    ref_titled = df[df['id'] == ref].title.values[0]\n",
    "                    refs_titled.append(ref_titled)\n",
    "            \n",
    "            # Once/if all the ids are in the database we can take this if else out\n",
    "            if not refs_titled: # none of the cited paper ids were in the df\n",
    "                f.write(str({\"id\": paper_id, \"title\": title}))\n",
    "            else: \n",
    "                f.write(str({\"id\": paper_id, \"title\": title, \"refs\": refs_titled}))\n",
    "\n",
    "end_time = time.time()\n",
    "seconds_elapsed = end_time-start_time\n",
    "minutes_elapsed = (end_time-start_time)/60\n",
    "print(\"Query completed in {:.2f} seconds.\".format(seconds_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the json\n",
    "with open('/Users/timholdsworth/code/scaling-science/notebooks/data/v1/mag_1e3.txt') as f:\n",
    "    data = f.readline()\n",
    "    jsondata = json.loads(data)\n",
    "    print(jsondata['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask - Task Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_json(file, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a given row (paper), returns the data to be written to the file\n",
    "\n",
    "def make_paper():\n",
    "    data = {\"id\": row[1][5],\n",
    "        \"title\": row[1][14],\n",
    "        \"refs\": row[1][13]}\n",
    "    \n",
    "    print(data)\n",
    "    return data \n",
    "\n",
    "res = df.apply(make_paper(), axis=1)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The dict takes up GB:\", sys.getsizeof(id_dict)/1000000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
