{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to graph database with 439,366,337 nodes and 648,637,424 relationships!\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "import glob, os, time\n",
    " \n",
    "graph = Graph('bolt://neo4j-magtwo:7687', auth=('neo4j','myneo'))\n",
    "#graph = Graph('bolt://localhost:7687', auth=('neo4j', 'password'))\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add uniqueness constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE CONSTRAINT ON (n:Quanta) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT ON (t:Tag) ASSERT t.name IS UNIQUE;\n",
      "CREATE CONSTRAINT ON (a:Author) ASSERT a.id IS UNIQUE;\n",
      "CREATE CONSTRAINT ON (o:Organization) ASSERT o.name IS UNIQUE;\n",
      "CREATE CONSTRAINT ON (v:Venue) ASSERT v.id IS UNIQUE;\n",
      "CREATE CONSTRAINT ON (v:Venue) ASSERT v.name IS UNIQUE;\n"
     ]
    }
   ],
   "source": [
    "contraint_node_property_pairs = [('n:Quanta', 'n.id'),\n",
    "                                 ('t:Tag', 't.name'),\n",
    "                                 ('a:Author', 'a.id'),\n",
    "                                 ('o:Organization', 'o.name'),\n",
    "                                 ('v:Venue', 'v.id'),\n",
    "                                ('v:Venue', 'v.name')]\n",
    "for n, p in contraint_node_property_pairs:\n",
    "    query = \"CREATE CONSTRAINT ON ({}) ASSERT {} IS UNIQUE;\".format(n,p)\n",
    "    print(query)\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE INDEX ON :Quanta(year);\n",
      "CREATE INDEX ON :Quanta(lang);\n",
      "CREATE INDEX ON :Quanta(keywords);\n",
      "CREATE INDEX ON :Quanta(title);\n",
      "CREATE INDEX ON :Quanta(venue);\n",
      "CREATE INDEX ON :Quanta(doctype);\n",
      "CREATE INDEX ON :Venue(name);\n",
      "CREATE INDEX ON :Year(value);\n",
      "CREATE INDEX ON :Author(name);\n",
      "CREATE INDEX ON :Author(normalizedName);\n"
     ]
    }
   ],
   "source": [
    "indices_to_create = [':Quanta(year)', ':Quanta(lang)', ':Quanta(keywords)', \n",
    "                     ':Quanta(title)', ':Quanta(venue)', ':Quanta(doctype)',\n",
    "                     ':Venue(normalizedName)', ':Year(value)',\n",
    "                     ':Author(name)', ':Author(normalizedName)']\n",
    "for index in indices_to_create:\n",
    "    query = \"CREATE INDEX ON {};\".format(index)\n",
    "    print(query)\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory set to ``.\n"
     ]
    }
   ],
   "source": [
    "# Set data directory. In Neo4j 3.5+, the directory is automatically set to /import\n",
    "data_dir = '' \n",
    "#data_dir = 'file:/Users/timholdsworth/code/scaling-science/notebooks/data/'\n",
    "\n",
    "venues_file = data_dir + 'magtwo/mag_venues.txt'\n",
    "papers_files = [data_dir + 'magtwo/mag_papers_{}.txt'.format(i) for i in range(11)]\n",
    "authors_files = [data_dir + 'magtwo/mag_authors_{}.txt'.format(i) for i in range(13)]\n",
    "\n",
    "v1_papers_files = [data_dir + 'magone/mag_papers_{}.txt'.format(i) for i in range(167)]\n",
    "v1_papers_files_clean = [data_dir + 'magone/mag_papers_{}_clean.txt'.format(i) for i in range(167)]\n",
    "\n",
    "print(\"Data directory set to `{}`.\".format(data_dir))\n",
    "\n",
    "def run_query(query, graph, print_query=False, run_query=True, print_only=False):\n",
    "    if print_only: \n",
    "        print_query = True\n",
    "        run_query = False\n",
    "    start_time = time.time()\n",
    "    if print_query:\n",
    "        print(query)\n",
    "    if run_query:\n",
    "        graph.run(query)\n",
    "    end_time = time.time()\n",
    "    seconds_elapsed = end_time-start_time\n",
    "    minutes_elapsed = (end_time-start_time)/60\n",
    "    print(\"Query completed in {:.2f} seconds.\".format(seconds_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import venues as nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed in 2.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" \n",
    "CALL apoc.periodic.iterate(\n",
    "\"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "\"CREATE (v:Venue {{id:q.id, journalId:q.JournalId, conferenceId:q.ConferenceId,\n",
    "    name:q.DisplayName, normalizedName:q.NormalizedName}})\", \n",
    "{{batchSize:10000, iterateList:true, parallel:true}});\n",
    "\"\"\".format(venues_file)\n",
    "\n",
    "run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create year nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed in 0.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "UNWIND range(1800, 2020) as yr\n",
    "MERGE (y:Year {value: yr})\n",
    "\"\"\"\n",
    "run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import quanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing magtwo/mag_papers_0.txt\n",
      "Query completed in 627.13 seconds.\n",
      "Importing magtwo/mag_papers_1.txt\n",
      "Query completed in 686.22 seconds.\n",
      "Importing magtwo/mag_papers_2.txt\n",
      "Query completed in 688.79 seconds.\n",
      "Importing magtwo/mag_papers_3.txt\n",
      "Query completed in 692.98 seconds.\n",
      "Importing magtwo/mag_papers_4.txt\n",
      "Query completed in 674.89 seconds.\n",
      "Importing magtwo/mag_papers_5.txt\n",
      "Query completed in 906.51 seconds.\n",
      "Importing magtwo/mag_papers_6.txt\n",
      "Query completed in 789.81 seconds.\n",
      "Importing magtwo/mag_papers_7.txt\n",
      "Query completed in 878.28 seconds.\n",
      "Importing magtwo/mag_papers_8.txt\n",
      "Query completed in 1607.13 seconds.\n",
      "Importing magtwo/mag_papers_9.txt\n",
      "Query completed in 1362.97 seconds.\n",
      "Importing magtwo/mag_papers_10.txt\n",
      "Query completed in 45.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "#for file_name in papers_files:\n",
    "for file_name in papers_files:\n",
    "    print('Importing {}'.format(file_name))\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q\",\n",
    "    \"CREATE (p:Quanta {{id:q.id, title:q.title, year:q.year, keywords:q.keywords,\n",
    "        numCitations:q.n_citation, docType:q.doc_type, language:q.lang, \n",
    "        publisher:q.publisher, doi:q.doi, pdf:q.pdf, abstract:q.abstract}})\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)\n",
    "    \n",
    "# CREATE (p:Quanta {{id:q.id, title:q.title, year:q.year, keywords:q.keywords,\n",
    "#        numCitations:q.n_citation, docType:q.doc_type, language:q.lang, \n",
    "#        publisher:q.publisher, doi:q.doi, pdf:q.pdf, abstract:q.abstract\n",
    "\n",
    "#MERGE (p:Quanta {{id:q.id}}) \n",
    "#        ON CREATE SET title=q.title, year=q.year, keywords=q.keywords,\n",
    "#        numCitations=q.n_citation, docType=q.doc_type, language=q.lang, \n",
    "#        publisher=q.publisher, doi=q.doi, pdf=q.pdf, abstract=q.abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create relationships between quanta and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in papers_files:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (p:Quanta {{id:q.id}})\n",
    "    WITH p\n",
    "    MATCH (y:Year {{value: p.year}})\n",
    "    CREATE (p)-[:PUBLISHED_IN_YEAR]->(y)\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)\n",
    "    \n",
    "# Changing q to p in value:p.year because year value on the node should be same\n",
    "# as the year value on corresponding node in the map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create relationships between Quanta and Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing magtwo/mag_papers_0.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_0.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_1.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_1.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_2.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_2.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_3.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_3.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_4.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_4.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_5.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_5.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_6.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_6.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_7.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_7.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_8.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_8.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_9.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_9.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n",
      "Importing magtwo/mag_papers_10.txt\n",
      "\n",
      "    CALL apoc.periodic.iterate(\n",
      "    \"CALL apoc.load.json('magtwo/mag_papers_10.txt') YIELD value AS q RETURN q\",\n",
      "    \"MATCH (p:Quanta {id:q.id})\n",
      "    WITH q, p\n",
      "    UNWIND q.venue as venue\n",
      "    WITH distinct q, p, venue\n",
      "    MERGE (v:Venue {name: venue.raw})\n",
      "    WITH p, v\n",
      "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
      "    {batchSize:10000, iterateList:true, parallel:true})\n",
      "    \n",
      "Query completed in 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "for file_name in papers_files:\n",
    "    print('Importing {}'.format(file_name))\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (p:Quanta {{id:q.id}})\n",
    "    WITH q, p\n",
    "    UNWIND q.venue as venue\n",
    "    WITH distinct q, p, venue\n",
    "    MERGE (v:Venue {{name: venue.raw}})\n",
    "    WITH p, v\n",
    "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph, print_only=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed in 1468.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "call apoc.periodic.iterate(\n",
    "  'MATCH (q:Quanta)-[r:PUBLISHED_IN_VENUE]-(v:Venue)\n",
    "   RETURN r',\n",
    "  'DELETE r',\n",
    "  {batchSize:100000, iterateList:true})\n",
    "\"\"\"\n",
    "\n",
    "run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing magtwo/mag_authors_0.txt\n",
      "Query completed in 774.70 seconds.\n",
      "Importing magtwo/mag_authors_1.txt\n",
      "Query completed in 876.17 seconds.\n",
      "Importing magtwo/mag_authors_2.txt\n",
      "Query completed in 846.06 seconds.\n",
      "Importing magtwo/mag_authors_3.txt\n",
      "Query completed in 885.65 seconds.\n",
      "Importing magtwo/mag_authors_4.txt\n",
      "Query completed in 907.23 seconds.\n",
      "Importing magtwo/mag_authors_5.txt\n",
      "Query completed in 862.75 seconds.\n",
      "Importing magtwo/mag_authors_6.txt\n",
      "Query completed in 938.40 seconds.\n",
      "Importing magtwo/mag_authors_7.txt\n",
      "Query completed in 930.07 seconds.\n",
      "Importing magtwo/mag_authors_8.txt\n",
      "Query completed in 947.97 seconds.\n",
      "Importing magtwo/mag_authors_9.txt\n",
      "Query completed in 1157.62 seconds.\n",
      "Importing magtwo/mag_authors_10.txt\n",
      "Query completed in 1295.23 seconds.\n",
      "Importing magtwo/mag_authors_11.txt\n",
      "Query completed in 1342.64 seconds.\n",
      "Importing magtwo/mag_authors_12.txt\n",
      "Query completed in 1094.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "# updated version (experimental)\n",
    "for file_name in authors_files: \n",
    "    print('Importing {}'.format(file_name))\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MERGE (a:Author {{id:q.id, name:q.name}})\n",
    "    SET a.normalizedName=q.normalized_name, a.position=q.position, a.lastAffiliation=q.org,\n",
    "            a.numCitations=q.n_citation, a.numPublications=q.n_pubs, a.hIndex=q.h_index\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating authored relationships for magtwo/mag_authors_0.txt\n",
      "Query completed in 12384.75 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_1.txt\n",
      "Query completed in 5023.32 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_2.txt\n",
      "Query completed in 3520.30 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_3.txt\n",
      "Query completed in 3387.49 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_4.txt\n",
      "Query completed in 3514.79 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_5.txt\n",
      "Query completed in 2603.89 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_6.txt\n",
      "Query completed in 2428.73 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_7.txt\n",
      "Query completed in 2322.33 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_8.txt\n",
      "Query completed in 1601.37 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_9.txt\n",
      "Query completed in 1805.25 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_10.txt\n",
      "Query completed in 2039.73 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_11.txt\n",
      "Query completed in 2155.19 seconds.\n",
      "Creating authored relationships for magtwo/mag_authors_12.txt\n",
      "Query completed in 2001.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# New - create authored relationships\n",
    "for file_name in authors_files: \n",
    "    print('Creating authored relationships for {}'.format(file_name))\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (a:Author {{id:q.id}})\n",
    "    WITH q, a\n",
    "    UNWIND q.pubs as pubs\n",
    "    WITH a, pubs\n",
    "    MATCH (p:Quanta {{id:pubs.i}})\n",
    "    WITH a, p, pubs\n",
    "    MERGE (a)-[r:AUTHORED {{order: pubs.r}}]->(p)\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:false}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)\n",
    "    #graph.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    {'name': '阚乃庆', 'id': '1000007673', 'normalize...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH (a:Author {id:'1000007673'}) RETURN (a)\n",
    "\"\"\" \n",
    "a = graph.run(query).to_data_frame()\n",
    "a.iloc[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old\n",
    "for file_name in papers_files:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (p:Quanta {{id:q.id}})\n",
    "    WITH p\n",
    "    MATCH (y:Year {{value: p.year}})\n",
    "    CREATE (p)-[:PUBLISHED_IN_YEAR]->(y)\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)\n",
    "    \n",
    "# Changing q to p in value:p.year because year value on the node should be same\n",
    "# as the year value on corresponding node in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE TO UPDATE STUFF THAT WAS WRONG\n",
    "\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (a:Author {{id:q.id}})\n",
    "    SET a.lastAffiliation=q.org, a.name:q.name, a.normalizedName=q.normalized_name\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create relationships between Authors and Quanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed in 458.34 seconds.\n",
      "Query completed in 188.45 seconds.\n",
      "Query completed in 182.63 seconds.\n",
      "Query completed in 230.54 seconds.\n",
      "Query completed in 318.06 seconds.\n",
      "Query completed in 298.09 seconds.\n",
      "Query completed in 292.88 seconds.\n",
      "Query completed in 176.00 seconds.\n",
      "Query completed in 134.22 seconds.\n",
      "Query completed in 216.26 seconds.\n",
      "Query completed in 223.89 seconds.\n",
      "Query completed in 120.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "# updated version (experimental)\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (a:Author {{id:q.id}})\n",
    "    WITH q, a\n",
    "    UNWIND q.pubs as pubs\n",
    "    MATCH (p:Quanta {{id:pubs.i}})\n",
    "    MERGE (a)-[r:AUTHORED]->(p)\n",
    "    ON CREATE SET r.order = CASE WHEN pubs.r IS NULL THEN NULL ELSE pubs.r END\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 2\n",
    "for file_name in papers_files[0:1]:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MATCH (p:Quanta {{id:q.id}})\n",
    "    WITH p, q, range(0, size(q.authors)) as is\n",
    "    UNWIND is as i\n",
    "    MATCH (a:Author)\n",
    "    WHERE \n",
    "        CASE WHEN ((a.id IS NULL) OR (q.authors[i].id IS NULL))\n",
    "        THEN (a.name=q.authors[i].name)\n",
    "        ELSE (a.id=q.authors[i].id)\n",
    "        END\n",
    "    WITH p, a, i\n",
    "    MERGE (p)-[r:AUTHORED]->(a)\n",
    "    SET r.order = i\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add organization nodes\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"WHERE q.org is not null\n",
    "        MERGE (o:Organization {{name: q.org}})\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add relationships between Authors and Org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships between authors and organizations\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"MATCH (a:Author {{id: q.id}})\n",
    "        MATCH (o:Organization {{name: q.org}})\n",
    "        WITH q, a, o\n",
    "        WHERE q.org is not null\n",
    "        MATCH (o:Organization {{name: q.org}})\n",
    "        MERGE (a)-[:AFFILIATED_WITH]->(o)\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags as nodes\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"UNWIND q.tags as tags\n",
    "        MERGE (t:Tag {{name: tags.t}})\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add relationships between Authors and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships between authors and tags\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"UNWIND q.tags as tags\n",
    "        WITH q, tags\n",
    "        MATCH (a:Author {{id: q.id}})\n",
    "        MATCH (t:Tag {{name: tags.t}})\n",
    "        WITH a, t, i\n",
    "        MERGE (a)-[r:HAS_TAG]->(t)\n",
    "        SET r.weight = a.weight\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import citation data from MAGv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "Procedure Call Failed: Failed to invoke procedure `apoc.periodic.iterate`: Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('e' (code 101)): was expecting comma to separate Array entries\n at [Source: (apoc.export.util.CountingInputStream); line: 15, column: 3441]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCypherError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/neo4j/v1/api.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, statement, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/neo4j/bolt/connection.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown_errors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/neo4j/bolt/connection.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mlog_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"S: FAILURE (%r)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/neo4j/v1/result.py\u001b[0m in \u001b[0;36mon_failure\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mon_footer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCypherError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: Failed to invoke procedure `apoc.periodic.iterate`: Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('e' (code 101)): was expecting comma to separate Array entries\n at [Source: (apoc.export.util.CountingInputStream); line: 15, column: 3441]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-35731263bb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\".format(data_dir + file_name)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-0f5939bede3f>\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(query, graph, print_query, run_query, print_only)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mseconds_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseparate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCypherError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGraphError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"message\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: Procedure Call Failed: Failed to invoke procedure `apoc.periodic.iterate`: Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('e' (code 101)): was expecting comma to separate Array entries\n at [Source: (apoc.export.util.CountingInputStream); line: 15, column: 3441]"
     ]
    }
   ],
   "source": [
    "# Edit this so that it matches the ids from magv1 with the id properties on existing \n",
    "for file_name in v1_papers_files_clean:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"MATCH (p:Quanta {{title: q.title}})\n",
    "        UNWIND q.refs as ref\n",
    "        WITH p, ref\n",
    "        MATCH (b:Quanta {{title: ref}})\n",
    "        CREATE (p)-[:CITES]->(b)\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    \n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add coauthor relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "    \"MATCH (q:Quanta) WHERE size((q)<-[:AUTHORED]-()) > 1 RETURN q\",\n",
    "    \"WITH [(q)<-[:AUTHORED]-(a) | a] as coAuthors\n",
    "    UNWIND coAuthors as first\n",
    "    UNWIND coAuthors as second\n",
    "    WITH first, second\n",
    "    WHERE id(first) < id(second)\n",
    "    MERGE (first)-[r:COAUTHOR]-(second)\n",
    "    SET r.strength = CASE WHEN r.strength IS NULL THEN 1 ELSE r.strength + 1 END\",\n",
    "{batchSize:10000, iterateList:true, parallel:true});\n",
    "\"\"\"\n",
    "run_query(query, graph, print_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD IMPORTS BELOW HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import quanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#for file_name in papers_files:\n",
    "for file_name in papers_files:\n",
    "    print('Importing {}'.format(file_name))\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MERGE (p:Quanta {{id:q.id, title:q.title, year:q.year, keywords:q.keywords,\n",
    "        numCitations:q.n_citation, docType:q.doc_type, language:q.lang, \n",
    "        publisher:q.publisher, doi:q.doi, pdf:q.pdf, abstract:q.abstract}})\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete relationships between Quanta and Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (:Quanta)-[r:PUBLISHED_IN_VENUE]-(:Venue) \n",
    "DELETE r\n",
    "\"\"\"\n",
    "run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import quanta, authors, and add relationships to author and venue nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in papers_files:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"UNWIND q.id as id\n",
    "    CREATE (p:Quanta {{id:id, title:q.title, year:q.year, keywords:q.keywords,\n",
    "        numCitations:q.n_citation, docType:q.doc_type, language:q.lang, \n",
    "        publisher:q.publisher, doi:q.doi, pdf:q.pdf, abstract:q.abstract}})\n",
    "    WITH q, p\n",
    "    MATCH (y:Year {{value: q.year}})\n",
    "    CREATE (p)-[:PUBLISHED_IN_YEAR]->(y)\n",
    "    WITH q, p\n",
    "    UNWIND q.venue as venue\n",
    "    MATCH (v:Venue {{name: venue.raw }})\n",
    "    CREATE (p)-[:PUBLISHED_IN_VENUE]->(v)\n",
    "    WITH q, p\n",
    "    UNWIND range(0, size(q.authors)-1) as i\n",
    "    MERGE (a:Author {{id:q.authors[i].id, name:q.authors[i].name}})\n",
    "    CREATE (a)-[:AUTHORED {{rank:i}}]->(p)\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:false}});\n",
    "    \"\"\".format(file_name)\n",
    "    run_query(query, graph, print_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Author, Tag, and Organization nodes and relationships between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import authors and make relationships between authors and quanta\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "    \"MERGE (a:Author {{id:q.id, name:q.name}})\n",
    "        SET a.normalizedName=q.normalized_name, a.position=q.position, \n",
    "            a.numCitations=q.n_citation, a.numPublications=q.n_pubs, a.hIndex=q.h_index)\n",
    "    WITH q, a\n",
    "    UNWIND q.pubs as pubs\n",
    "    MATCH (p:Quanta {{id:pubs.i}})\n",
    "    MERGE (a)-[r:AUTHORED]->(p)\n",
    "    SET  rrank=pubs.r\",\n",
    "    {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add organization nodes\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"CREATE (o:Organization {{name: q.org}})\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships between authors and organizations\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"MATCH (a:Author {{normalizedName: q.normalized_name}})\n",
    "        MATCH (o:Organization {{name: q.org}})\n",
    "        WHERE q.org is not null\n",
    "        CREATE (a)-[:AFFILIATED_WITH]->(o)\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags as nodes\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"UNWIND q.tags as tags\n",
    "        MERGE (t:Tag {{name: tags.t}})\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}})\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships between authors and tags\n",
    "for file_name in authors_files: \n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"UNWIND q.tags as tags\n",
    "        MATCH (a:Author {{normalizedName: q.normalized_name}})\n",
    "        MATCH (t:Tag {{name: tags.t}})\n",
    "        CREATE (a)-[:HAS_TAG {{weight: tags.weight}}]->(t)\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Citation Data from MAGv1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this so that it matches the ids from magv1 with the id properties on existing \n",
    "for file_name in v1_papers_files:\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"CALL apoc.load.json('{}') YIELD value AS q RETURN q\",\n",
    "        \"MATCH (a:Quanta {{title: q.title}})\n",
    "        WITH a\n",
    "        UNWIND q.refs as ref\n",
    "        MATCH (b:Quanta {{title: ref}})\n",
    "        CREATE (a)-[:CITES]->(b)\",\n",
    "        {{batchSize:10000, iterateList:true, parallel:true}});\n",
    "    \"\"\".format(data_dir + file_name)\n",
    "    \n",
    "run_query(query, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Coauthor Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "    \"MATCH (q:Quanta) WHERE size((q)<-[:AUTHORED]-()) > 1 RETURN q\",\n",
    "    \"WITH [(q)<-[:AUTHORED]-(a) | a] as coAuthors\n",
    "    UNWIND coAuthors as first\n",
    "    UNWIND coAuthors as second\n",
    "    WITH first, second\n",
    "    WHERE id(first) < id(second)\n",
    "    MERGE (first)-[r:COAUTHOR]-(second)\n",
    "    SET r.strength = CASE WHEN r.strength IS NULL THEN 1 ELSE r.strength + 1 END\",\n",
    "{batchSize:10000, iterateList:true, parallel:true});\n",
    "\"\"\"\n",
    "run_query(query, graph, print_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
