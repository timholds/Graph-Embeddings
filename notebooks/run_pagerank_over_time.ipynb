{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to graph database with 166,192,182 nodes and 611,200,000 relationships!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "      graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIRST ATTEMPT AT A QUERY THAT WRITES pagerank PROPERTY TO THE ENTIRE GRAPH\n",
    "# import pandas as pd\n",
    "\n",
    "# print(\"Running PageRank STREAM on the entire graph...\", end=\" \", flush=True)\n",
    "# query = \"\"\"\n",
    "# CALL algo.pageRank.stream('Quanta','CITES',{iterations:20, concurrency:20})\n",
    "# YIELD node, score\n",
    "# RETURN node.id, node.title, score\n",
    "# LIMIT 1000\n",
    "# \"\"\"\n",
    "# df = graph.run(query).to_data_frame()\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Attempt non-streaming version of pagerank \n",
    "# print(\"Running  PageRank on entire graph...\", end=\" \")\n",
    "# query = \"\"\"\n",
    "# CALL algo.pageRank(\n",
    "# 'Quanta',\n",
    "# 'CITES',\n",
    "# {iterations:20, write: true, writeProperty:'pageRank2018'});\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run non-streaming PageRank on each year from 1800 to 1805\n",
    "\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# start_year, end_year, step = 1900, 1920, 5\n",
    "# dfs = []\n",
    "# start_time = time.time()\n",
    "# for year in range(start_year, end_year+1, step):\n",
    "\n",
    "#     print(\"Running PageRank on works from <= {}...\".format(year), end=\" \")\n",
    "#     query = \"\"\"\n",
    "#     CALL algo.pageRank(\n",
    "#     'MATCH (p:Quanta) WHERE p.year <= {} RETURN id(p) as id',\n",
    "#     'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "#     {{graph:'cypher', writeProperty:'pageRank_{}', iterations:5, write: true, concurrency:20}});\n",
    "#     \"\"\".format(year,year)\n",
    "#     graph.run(query).evaluate()\n",
    "    \n",
    "#     print(\"Pulling out and saving results...\", end=\" \")\n",
    "#     query = \"\"\"\n",
    "#     MATCH (a:Quanta) \n",
    "#     WHERE a.year <= {} \n",
    "#     RETURN id(a), a.title, a.pageRank_{}\"\"\".format(year,year)\n",
    "#     df = graph.run(query).to_data_frame()\n",
    "#     df['year'] = year\n",
    "#     dfs.append(df)\n",
    "#     print(\"Done.\")\n",
    "    \n",
    "# end_time = time.time()\n",
    "# print(end_time-start_time)\n",
    "# # result = pd.concat(dfs).pivot_table(index='a.title', columns='year', values='a.pageRank')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PageRank on works from < 1950... Done (100.33 minutes).\n",
      "Running PageRank on works from < 1960... Done (47.19 minutes).\n",
      "Running PageRank on works from < 1970... Done (44.08 minutes).\n",
      "Running PageRank on works from < 1980... Done (44.80 minutes).\n",
      "Running PageRank on works from < 1990... Done (46.91 minutes).\n",
      "Running PageRank on works from < 2000... Done (49.85 minutes).\n",
      "Running PageRank on works from < 2010... Done (56.03 minutes).\n",
      "Running PageRank on works from < 2020... Done (60.00 minutes).\n",
      "Finished all calculations in 449.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Run STREAMING PageRank on each year from 1800 to 1805\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "start_year, end_year, step = 1950, 2020, 10\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1, step):\n",
    "    \n",
    "    # < IS MUCH FASTER THAN <=\n",
    "    print(\"Running PageRank on works from < {}...\".format(year), end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank.stream(\n",
    "    'MATCH (p:Quanta) WHERE p.year < {} RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', iterations:5, concurrency:20}})\n",
    "    YIELD node, score\n",
    "    WITH * \n",
    "    ORDER BY score DESC\n",
    "    LIMIT 1000\n",
    "    RETURN node.id as id, node.title as title, node.lang as lang, node.year as year, \n",
    "    node.keywords as keywords, node.fos as fos, score;\n",
    "    \"\"\".format(year,year)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "    query_end_time = time.time()\n",
    "    print(\"Done ({:.2f} minutes).\".format((query_end_time-query_start_time)/60))\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to /tmp/data/impactByTitle_166M_1950-2020-10.csv... Done.\n"
     ]
    }
   ],
   "source": [
    "# Write result BY TITLE to CSV\n",
    "result = pd.concat(dfs).pivot_table(index='title', columns='year', values='score')    \n",
    "file_path = '/tmp/data/result/impactByTitle_166M_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.index = result.index.str.replace(\",\",\"\")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graph loading (notes; do not execute)\n",
    "# # // Load graph\n",
    "CALL algo.graph.load('my-graph','Label','REL_TYPE',{graph:'heavy',..other config...})\n",
    "  YIELD name, graph, direction, undirected, sorted, nodes, loadMillis, alreadyLoaded,\n",
    "        nodeWeight, relationshipWeight, nodeProperty, loadNodes, loadRelationships;\n",
    "\n",
    "# # // Info on loaded graph\n",
    "# CALL algo.graph.info('my-graph')\n",
    "#   YIELD name, type, exists, removed, nodes;\n",
    "\n",
    "# # // Use graph\n",
    "# CALL algo.pageRank(null,null,{graph:'my-graph',...})\n",
    "\n",
    "\n",
    "# # // Remove graph\n",
    "# CALL algo.graph.remove('my-graph')\n",
    "#   YIELD name, type, exists, removed, nodes;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
