{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert H5 files to CSV for Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "data_files = glob.glob('/tmp/data/patents/*.h5')\n",
    "for file in data_files:\n",
    "    \n",
    "    print(\"Reading {}...\".format(file), end=\" \")\n",
    "    df = pd.read_hdf(file)\n",
    "    df.columns = ['title','inventors','pub_date','classifications','n_citations',\n",
    "                  'cited_by', 'patent_citations','also_published_as','location']\n",
    "    df['title'] = df['title'].str.strip()\n",
    "    df['classifications'] = df['classifications'].str.join(\";\")\n",
    "    df['inventors'] = df['inventors'].str.join(\";\")\n",
    "    df['cited_by'] = df['cited_by'].str.join(\";\")\n",
    "    df['patent_citations'] = df['patent_citations'].str.join(\";\")\n",
    "    df['also_published_as'] = df['also_published_as'].str.join(\";\")\n",
    "#     df.replace(\"\", np.nan, inplace=True)\n",
    "    assert(not df.index.duplicated().any())\n",
    "    \n",
    "    new_file = file.replace('.h5','.csv')\n",
    "    print(\"Writing {}...\".format(new_file), end=\" \")\n",
    "    df.to_csv(path_or_buf=new_file, sep=',', quoting=csv.QUOTE_MINIMAL, chunksize=50000, index_label='number', na_rep='na')\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need to do something with the ALSO published as\n",
    "# sum(df['also_published_as'].str.len())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "graph = Graph(\"bolt://neo4j:7687\")\n",
    "\n",
    "#graph.delete_all()\n",
    "\n",
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constrain one id per Patent\n",
    "# print(\"Creating uniqueness constraint (and also index) on Patent numbers...\", end=\" \", flush=True)\n",
    "# query = \"\"\"CREATE CONSTRAINT ON (n:Patent) ASSERT n.number IS UNIQUE;\"\"\"\n",
    "# graph.run(query).evaluate()\n",
    "# print(\"Done.\")\n",
    "\n",
    "# Add index for number\n",
    "print(\"Creating uniqueness constraint for id...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (n:Patent) ASSERT n.id IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for classifications\n",
    "print(\"Creating index for classifications...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Patent(classifications);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# # Add index for inventors\n",
    "# print(\"Creating index for inventors...\", end=\" \", flush=True)\n",
    "# query = \"\"\"CREATE INDEX ON :Patent(inventors);\"\"\"\n",
    "# graph.run(query).evaluate()\n",
    "# print(\"Done.\")\n",
    "\n",
    "# Add index for location\n",
    "print(\"Creating index for location...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Patent(location);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for pub_date\n",
    "print(\"Creating index for pub_date...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Patent(pub_date);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import patents\n",
    "\n",
    "local_data_dir = '/tmp/data/test/patents/'\n",
    "neo4j_data_dir = '/import/test/patents/'\n",
    "\n",
    "import glob, os, time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _, _, files in os.walk(local_data_dir):\n",
    "    for file in sorted(files):\n",
    "        if file.endswith('.csv'):\n",
    "            print(\"Importing {}...\".format(file), end=\" \", flush=True)\n",
    "            query_start_time = time.time()\n",
    "            query = \"\"\"\n",
    "            CALL apoc.periodic.iterate(\"\n",
    "                CALL apoc.load.csv(\n",
    "                    'file://{}{}',\n",
    "                    {{\n",
    "                     header:true,sep:',',\n",
    "                     mapping:{{\n",
    "                      number:{{name:'id'}},\n",
    "                      patent_citations:{{name:'refs',array:true,arraySep:';'}},\n",
    "                      also_published_as:{{array:true,arraySep:';'}},\n",
    "                      cited_by:{{array:true,arraySep:';'}},\n",
    "                      inventors:{{name:'authors',array:true,arraySep:';'}},\n",
    "                      n_citations:{{name:'n_citation',type:'int',arraySep:';'}},\n",
    "                      classifications:{{array:true,arraySep:';'}},\n",
    "                      location:{{}}\n",
    "                    }}\n",
    "                }}) YIELD map as row \n",
    "                RETURN row\n",
    "            \",\n",
    "            \"CREATE (p:Patent) SET p = row\n",
    "                SET p.patent_citations = [f IN p.patent_citations WHERE f <> '']\n",
    "                SET p.also_published_as = [f IN p.also_published_as WHERE f <> '']\n",
    "                SET p.cited_by = [f IN p.cited_by WHERE f <> '']\n",
    "                SET p.authors = [f IN p.authors WHERE f <> '']\n",
    "                SET p.classifications = [f IN p.classifications WHERE f <> '']\n",
    "                SET p.year = toInt(head(split(p.pub_date,'-')))\n",
    "            \", \n",
    "            {{batchsize:20000, iterateList:true, parallel:false}}\n",
    "            );\n",
    "            \"\"\".format(neo4j_data_dir, file)\n",
    "#             print(query)\n",
    "            graph.run(query).evaluate()\n",
    "            query_end_time = time.time()\n",
    "            print(\"Done ({:.2f} minutes).\".format((query_end_time-query_start_time)/60))\n",
    "            \n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating uniqueness constraint for author...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Creating AUTHORED relationships...\", end=\" \")\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "\"MATCH (p:Patent) UNWIND p.authors AS auth  RETURN p, auth\"\n",
    ",\n",
    "\"MERGE (a:Author {name: auth}) \n",
    "MERGE (a)-[:AUTHORED {is_first_author: head(p.authors)=auth, is_last_author: last(p.authors)=auth}]->(p)\"\n",
    ",\n",
    "{batchSize:50, iterateList:true, parallel:false})\n",
    "\"\"\"\n",
    "\n",
    "# # other option\n",
    "# query = \"\"\"\n",
    "# CALL apoc.periodic.commit(\n",
    "# \"MATCH (p:Patent) \n",
    "# UNWIND p.authors AS auth\n",
    "# WITH p, auth\n",
    "# MERGE (a:Author {name: auth}) \n",
    "# MERGE (a)-[:AUTHORED {is_first_author: head(p.authors)=auth, is_last_author: last(p.authors)=auth}]->(p)\"\n",
    "# ,\n",
    "# {limit:10000})\n",
    "# \"\"\"\n",
    "\n",
    "#print(query)\n",
    "graph.run(query).evaluate()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding CITES relationships...\", end=\" \", flush=True)\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "\"MATCH (a:Patent) UNWIND a.cited_by AS ref RETURN a, ref\",\n",
    "\"MATCH (b:Patent {id: ref}) \n",
    "MERGE (b)-[:CITES]->(a)\",\n",
    "{batchSize:100, iterateList:true, parallel:false})\n",
    "\"\"\"\n",
    "\n",
    "# query = \"\"\"\n",
    "# CALL apoc.periodic.commit(\n",
    "# \"MATCH (p:Patent) UNWIND p.cited_by AS ref\n",
    "# WITH p, ref\n",
    "# MATCH (b:Patent {id: ref}) \n",
    "# MERGE (b)-[:CITES]->(p)\"\n",
    "# ,\n",
    "# {limit:1000})\n",
    "# \"\"\"\n",
    "\n",
    "#print(query)\n",
    "graph.run(query).evaluate()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Built a graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PageRank once on entire graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "print(\"Running PageRank on all patents...\", end=\" \")\n",
    "# query = \"\"\"\n",
    "# CALL algo.pageRank.stream(\n",
    "#     'MATCH (p:Patent) RETURN id(p) as id'\n",
    "#     ,\n",
    "#     'MATCH (p1:Patent)-[:CITES]->(p2:Patent) RETURN id(p1) as source, id(p2) as target'\n",
    "#     ,\n",
    "#     {graph:'cypher', iterations:20, write:true, writeProperty:'pagerank'}\n",
    "#     )\n",
    "# YIELD node, score\n",
    "# WITH * \n",
    "# ORDER BY score DESC\n",
    "# LIMIT 50\n",
    "# RETURN node.number AS number, \n",
    "#     node.title AS title, \n",
    "#     node.inventors AS inventors, \n",
    "#     node.location AS location, \n",
    "#     node.n_citations AS n_citations, \n",
    "#     node.pub_date AS pub_date, \n",
    "#     node.patent_citations AS patent_citations, \n",
    "#     node.classifications AS classifications, \n",
    "#     node.cited_by AS cited_by, \n",
    "#     score;\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "CALL algo.pageRank(\n",
    "    'MATCH (p:Patent) RETURN id(p) as id'\n",
    "    ,\n",
    "    'MATCH (p1:Patent)-[:CITES]->(p2:Patent) RETURN id(p1) as source, id(p2) as target'\n",
    "    ,\n",
    "    {graph:'cypher', iterations:30, write:true, writeProperty:'pagerank'}\n",
    "    );\n",
    "\"\"\"\n",
    "#print(query)\n",
    "df = graph.run(query).to_data_frame()\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PageRank over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run STREAMING PageRank on each year from 1800 to 1805\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "start_year, end_year, step = 1900, 2020, 5\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1, step):\n",
    "    \n",
    "    # < IS MUCH FASTER THAN <=\n",
    "    print(\"Running PageRank on patents from < {}...\".format(year), end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank.stream(\n",
    "         'MATCH (p:Patent) WHERE p.pub_date < \"{}-01-01\" AND p.pub_date <> \"\" RETURN id(p) as id'\n",
    "        ,'MATCH (p1:Patent)-[:CITES]->(p2:Patent) RETURN id(p1) as source, id(p2) as target'\n",
    "        ,{{graph:'cypher', iterations:20, write:false}})\n",
    "    YIELD node, score\n",
    "    WITH * \n",
    "    ORDER BY score DESC\n",
    "    LIMIT 50\n",
    "    RETURN \n",
    "        node.number AS number, \n",
    "        node.title AS title, \n",
    "        node.inventors AS inventors, \n",
    "        node.location AS location, \n",
    "        node.n_citations AS n_citations, \n",
    "        node.pub_date AS pub_date, \n",
    "        node.patent_citations AS patent_citations, \n",
    "        node.classifications AS classifications, \n",
    "        node.cited_by AS cited_by, \n",
    "        score;\n",
    "    \"\"\".format(year)\n",
    "    #print(query)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "    query_end_time = time.time()\n",
    "    print(\"Done ({:.2f} minutes).\".format((query_end_time-query_start_time)/60))\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(dfs)\n",
    "all_results_path = '/tmp/data/result/patents_pagerank_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing all results to {}...\".format(all_results_path), end=\" \")\n",
    "all_results.to_csv(path_or_buf=all_results_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# all_results['title_clean'] = all_results['title'].str.replace(',',' ')\n",
    "result = all_results.pivot_table(index=['title','number'], columns='year', values='score')    \n",
    "\n",
    "file_path = '/tmp/data/result/patents_pivottable_{}-{}-{}.csv'.format(start_year, end_year,step)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top patents in Boston/MA/Cambridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()    \n",
    "print(\"Getting top Boston/MA/Cambridge inventors and patents...\", end=\" \")\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Author)-[:AUTHORED]->(p:Patent)\n",
    "WHERE \n",
    "    toUpper(p.location) CONTAINS \"BOSTON\" OR\n",
    "    toUpper(p.location) CONTAINS \"MASSACHUSETTS\" OR\n",
    "    toUpper(p.location) = \"MA\" OR\n",
    "    toUpper(p.location) CONTAINS \"CAMBRIDGE\"\n",
    "WITH a\n",
    "MATCH (a:Author)-[:AUTHORED]->(b:Patent)\n",
    "RETURN \n",
    "    a.name AS name, \n",
    "    COUNT(b) AS total_patents,\n",
    "    SUM(b.n_citation) AS total_citations, \n",
    "    SUM(b.pagerank) AS total_pagerank,\n",
    "    SUM(log(b.pagerank*exp((2018-b.year)/20))) AS impact\n",
    "ORDER BY impact DESC\n",
    "\"\"\"\n",
    "df = graph.run(query).to_data_frame()\n",
    "end_time = time.time()\n",
    "print(\"Finished all calculations in {:.2f} minutes.\".format((end_time-start_time)/60))\n",
    "print(df['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasify and rank patents by author gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, random\n",
    "from nltk.corpus import names as nltk_names\n",
    "\n",
    "nltk.download(\"names\")\n",
    "male_names = list(nltk_names.words('male.txt'))\n",
    "female_names = list(nltk_names.words('female.txt'))\n",
    "\n",
    "labeled_names = ([({\"name\": name}, 'male') for name in male_names])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_inventors = set()\n",
    "for name in df['name']:\n",
    "    first_name = name.split(' ')[0]\n",
    "    if first_name in female_names:\n",
    "        female_inventors.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_inventors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_patents = {}\n",
    "for patNum, name_lst in names.items():\n",
    "    to_add = []\n",
    "    for name in name_lst:\n",
    "        if len(name.first.split()) > 1:\n",
    "            fst_name = name.first.split()[0]\n",
    "        else:\n",
    "            fst_name = name.first\n",
    "        feat = {\"name\": fst_name}\n",
    "        res = classifier.classify(feat)\n",
    "        if res == \"female\":\n",
    "            to_add.append(name)\n",
    "    if not to_add == []:\n",
    "        female_patents[patNum] = to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
