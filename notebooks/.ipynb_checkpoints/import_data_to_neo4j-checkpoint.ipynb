{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "#from py2neo.Graph import database \n",
    "\n",
    "# Need to get authentication working, currently NEO4J_AUTH=none\n",
    "#graph = Graph(\"bolt://neo4j:7687\")\n",
    "graph = Graph('bolt://localhost:7687', bolt=True)\n",
    "\n",
    "graph.delete_all()\n",
    "\n",
    "#n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "#n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "#print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     #(n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain one id per Quanta\n",
    "print(\"Creating uniqueness constraint (and also index) on Quanta id's...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (n:Quanta) ASSERT n.id IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Constrain one name per author\n",
    "print(\"Creating uniqueness constraint (and also index) on Author names...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Constrain one name per author\n",
    "print(\"Creating uniqueness constraint (and also index) on Organization names...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE CONSTRAINT ON (o:Organization) ASSERT o.name IS UNIQUE;\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index for year of publication\n",
    "print(\"Creating index for publication year...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(year);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for language\n",
    "print(\"Creating index for langauge...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(lang);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for keywords HOW?\n",
    "print(\"Creating index for fos...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(fos);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Add index for title (good idea?)\n",
    "print(\"Creating index for title...\", end=\" \", flush=True)\n",
    "query = \"\"\"CREATE INDEX ON :Quanta(title);\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 adds Quanta, Authors, and Organizations to graph with relationships between\n",
    "# Authors and Quanta, and Authors and Orgs\n",
    "# query2 adds is_first_author and is_last_author property to AUTHORED relationships between\n",
    "# Authors and Quanta\n",
    "\n",
    "#local_data_dir = ‘/tmp/data/’\n",
    "#neo4j_data_dir = ‘/import/’\n",
    "\n",
    "local_data_dir = '/Users/timholdsworth/code/scaling-science/notebooks/tmp/data/'\n",
    "neo4j_data_dir = local_data_dir\n",
    "\n",
    "\n",
    "import glob, os\n",
    "for _,_ , files in os.walk(local_data_dir):\n",
    "    for file in sorted(files):\n",
    "        if file.endswith('.txt'):\n",
    "           \n",
    "           # Iterative query (more efficient)\n",
    "           print(\"Importing {}...\".format(file), end=\" \", flush=True)\n",
    "           query1 = \"\"\"\n",
    "           CALL apoc.periodic.iterate(\n",
    "           \"CALL apoc.load.json('file://{}{}') YIELD value AS q \n",
    "           RETURN q\",\n",
    "           \"UNWIND q.id AS id UNWIND q.authors as authors\n",
    "           MERGE (a:Author {{name:authors.name}})\n",
    "           MERGE (i:Quanta {{id:q.id}}) ON CREATE SET \n",
    "           i.refs=q.references, i.year=q.year, i.title=q.title, \n",
    "           i.fos=q.fos, i.url=q.url, i.lang=q.lang, i.keywords=q.keywords, \n",
    "           i.n_citation=q.n_citation, i.pdf=q.pdf, i.publisher=q.publisher\n",
    "           WITH a, q, authors\n",
    "           WHERE authors.org is not null\n",
    "           MERGE (o:Organization {{name:authors.org}}) \n",
    "           MERGE (a)-[:WORKS_AT]->(o)\", \n",
    "           {{batchSize:50000, iterateList:true, parallel:false}});\n",
    "           \"\"\".format(neo4j_data_dir, file)\n",
    "    \n",
    "           query2 = \"\"\"\n",
    "           CALL apoc.periodic.iterate(\n",
    "           \"CALL apoc.load.json('file://{}{}') YIELD value AS q RETURN q\",\n",
    "           \"UNWIND q.id AS id UNWIND q.authors as authors\n",
    "           WITH q.id AS id, head(q.authors).name as firstName, last(q.authors).name as lastName, q.authors as authors\n",
    "           UNWIND authors as author\n",
    "           MATCH (i:Quanta {{id:id}}) \n",
    "           MATCH (a:Author {{name:author.name}})\n",
    "           WITH i, a, author.name = firstName as isFirstName, author.name = lastName as isLastName\n",
    "           MERGE (a)-[r:AUTHORED]->(i) ON MATCH SET r.is_first_author=isFirstName, r.is_last_author=isLastName\",\n",
    "           {{batchSize:50000, iterateList:true, parallel:false}});\n",
    "           \"\"\".format(neo4j_data_dir, file)\n",
    "        \n",
    "           #print(query)\n",
    "           graph.run(query1).evaluate()\n",
    "           print(\"Done with query 1.\")\n",
    "           graph.run(query2).evaluate()\n",
    "           print(\"Done with query 2.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all citations as relationships between Quanta\n",
    "\n",
    "# # Simple but slow\n",
    "# query = \"\"\"\n",
    "# MATCH (a:Quanta), (b:Quanta)\n",
    "# WHERE a.id IN b.refs\n",
    "# CREATE (b)-[:CITES]->(a)\n",
    "# \"\"\"\n",
    "\n",
    "# # Faster but more complex (not benchmarked though)\n",
    "# query = \"\"\"\n",
    "# CALL apoc.periodic.iterate(\n",
    "#    \"MATCH (a:Quanta), (a2:Quanta) WHERE a.id IN a2.refs\n",
    "#     WITH a, COLLECT(a2) as b\n",
    "#     RETURN a, b\",\n",
    "#    \"UNWIND b AS a2\n",
    "#     CREATE (a2)-[:CITES]->(a)\",\n",
    "#     {batchSize:5000, parallel:true,iterateList:true}\n",
    "# \"\"\"\n",
    "\n",
    "# # Faster but simple (also not benchmarked)\n",
    "# query = \"\"\"\n",
    "# CALL apoc.periodic.iterate(\n",
    "#    \"MATCH (a:Quanta), (b:Quanta) WHERE ID(a) < ID(b) AND a.id IN b.refs RETURN a, b\",\n",
    "#    \"CREATE (b)-[:CITES]->(a)\",\n",
    "#     {batchSize:10000, parallel:true,iterateList:true});\n",
    "# \"\"\"\n",
    "\n",
    "# # Take advantage of indexing performed by constraints\n",
    "# print(\"Adding citations...\", end=\" \", flush=True)\n",
    "# query = \"\"\"\n",
    "# MATCH (b:Quanta)\n",
    "# UNWIND b.refs AS ref\n",
    "# MATCH (a:Quanta)\n",
    "# WHERE a.id = ref\n",
    "# CREATE (b)-[:CITES]->(a);\n",
    "# \"\"\"\n",
    "\n",
    "# # Take advantage of indexing and also run in batches\n",
    "# query = \"\"\"\n",
    "# CALL apoc.periodic.iterate(\n",
    "# \"MATCH (b:Quanta) \n",
    "#  UNWIND b.refs AS ref \n",
    "#  MATCH (a:Quanta) \n",
    "#  WHERE a.id = ref\n",
    "#  RETURN a, b\",\n",
    "# \"MERGE (b)-[:CITES]->(a)\",\n",
    "#  {batchSize:20000, parallel:false,iterateList:true});\n",
    "# \"\"\"\n",
    "\n",
    "# Fastest: Put more work on thread running in parallel. \n",
    "print(\"Adding citation relationships...\", end=\" \", flush=True)\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "\"MATCH (b:Quanta) UNWIND b.refs AS ref RETURN b, ref\",\n",
    "\"MATCH (a:Quanta {id: ref}) MERGE (b)-[:CITES]->(a)\",\n",
    "{batchSize:2000, iterateList:true, parallel:false})\n",
    "\"\"\"\n",
    "graph.run(query).evaluate()\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = graph.database.primitive_counts['NumberOfNodeIdsInUse']\n",
    "n_relationships = graph.database.primitive_counts['NumberOfRelationshipIdsInUse']\n",
    "print(\"Created graph database with {:,} nodes and {:,} relationships!\".format\n",
    "     (n_nodes, n_relationships))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various misc scripts below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PageRank on each year from 1800 to 1805\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "start_year, end_year = 1900, 1901\n",
    "dfs = []\n",
    "for year in range(start_year, end_year+1):\n",
    "\n",
    "    print(\"Running PageRank on works from <= {}...\".format(year), end=\" \")\n",
    "    query = \"\"\"\n",
    "    CALL algo.pageRank(\n",
    "    'MATCH (p:Quanta) WHERE p.year <= {} RETURN id(p) as id',\n",
    "    'MATCH (p1:Quanta)-[:CITES]->(p2:Quanta) RETURN id(p1) as source, id(p2) as target',\n",
    "    {{graph:'cypher', writeProperty:'pageRank_{}', iterations:5, write: true, concurrency:20}});\n",
    "    \"\"\".format(year,year)\n",
    "    graph.run(query).evaluate()\n",
    "    \n",
    "    print(\"Pulling out and saving results...\", end=\" \")\n",
    "    query = \"\"\"\n",
    "    MATCH (a:Quanta) \n",
    "    WHERE a.year <= {} \n",
    "    RETURN id(a), a.title, a.pageRank_{}\"\"\".format(year,year)\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "    print(\"Done.\")\n",
    "    \n",
    "result = pd.concat(dfs).pivot_table(index='a.title', columns='year', values='a.pageRank')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(dfs).pivot_table(index='a.title', columns='year', values='a.pageRank')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to CSV\n",
    "file_path = '/tmp/data/result/impact_20M_{}-{}.csv'.format(start_year, end_year)\n",
    "print(\"Writing results to {}...\".format(file_path), end=\" \")\n",
    "result.index = result.index.str.replace(\",\",\"\")\n",
    "result.to_csv(path_or_buf=file_path, sep=\",\", header=True, index=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "scores = result.sum(axis=1)\n",
    "scores.plot.hist(grid=True,bins=[i/2 for i in range(1,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = scores.quantile(0.999999)\n",
    "top_papers = scores.drop(scores[scores.values>=15].index)\n",
    "print(\"Considering the top {} (score >= {:.2f}) papers.\".format(len(top_papers), score_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "word_lists = top_papers.index.to_series().apply(\n",
    "    lambda x: [w for w in re.compile(r\"[A-Za-z']{4,}\").findall(x)])\n",
    "all_words = set()\n",
    "word_map = {}\n",
    "for i,v in word_lists.items():\n",
    "    for w in v:\n",
    "        all_words.add(w.lower())\n",
    "        word_map.get(w,[]).append(i)\n",
    "print(\"Built set and map of {:,} unique words.\".format(len(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filling {}x{} dataframe...\".format(len(all_words),len(result.columns)), end = \"\")\n",
    "word_scores = pd.DataFrame(0, index=all_words, columns=result.columns)\n",
    "for key, value in word_map:\n",
    "    print(key)\n",
    "#     for w in ws:\n",
    "#         print(w)\n",
    "#         word_scores.loc[w.lower()] += result.loc[title].va\n",
    "#         print(word_scores.loc[w.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_scores[title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[title,:]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
