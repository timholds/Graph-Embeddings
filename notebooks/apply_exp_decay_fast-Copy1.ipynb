{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     3
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'patents_pivottable_1900-2020-5.csv'\n",
    "root = '/Users/timholdsworth/code/scaling-science/data/result/'\n",
    "\n",
    "def get_data(file_name):\n",
    "    path_in = root + file_name\n",
    "    df = pd.read_csv(path_in, encoding='latin1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add extra columns that aggregate information from the dataframe\n",
    "def add_aggregate_cols(df):\n",
    "    # Add a column thats sums up all the values in a row, which are all the paper's pagerank scores in given years\n",
    "    df['score_sum'] = df.sum(axis=1, skipna=True)\n",
    "    # Add a column with the number of years since the paper was published\n",
    "    df['total_years_pub'] = len(df.columns) - 2 - df.isnull().sum(axis=1, skipna=True) \n",
    "    # Add a column with the average score for a paper\n",
    "    df['time_weighted_score'] = df['score_sum'] / df['total_years_pub']\n",
    "    return df\n",
    "\n",
    "#df = get_data(file_name)\n",
    "#df1 = add_aggregate_cols(df)\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by most impactful by average score over time, return num_results, round values, rename a column\n",
    "def clean_for_viz(df, num_results=None):\n",
    "    if num_results == None:\n",
    "        num_results = 100\n",
    "    \n",
    "    df = df.sort_values(by=['time_weighted_score'], ascending=False).reset_index(drop=True)\n",
    "    df = df.head(num_results)\n",
    "    df = df.round(3)\n",
    "    #df = df.rename(columns={\"a.title\": \"title\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes in data, finds most impactful papers, applies decay scores, writes these to csv\n",
    "def data_prep(file_name, num_results):\n",
    "    df = get_data(file_name)\n",
    "    df1 = add_aggregate_cols(df)\n",
    "    df2 = clean_for_viz(df1, num_results)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (27,) and (223,27) not aligned: 27 (dim 0) != 223 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-879ba101d373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-291-7021178bd452>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(file_name, num_results, decay_rate)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_aggregate_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_for_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mdf_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdf_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_linear_bycolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#df_norm = normalize(df_decay)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-299-879ba101d373>\u001b[0m in \u001b[0;36mdecay\u001b[0;34m(df, decay_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecay_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Put the columns back in their original order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (27,) and (223,27) not aligned: 27 (dim 0) != 223 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Take in undecayed scores and return a dataframe with the decayed scores\n",
    "def decay(df,decay_rate):\n",
    "    \n",
    "    #titles = df.index.values\n",
    "    #print(titles)\n",
    "    \n",
    "    # Reverse the order of the columns so we don't have to track NaNs and can multiply every row by same decay_vector\n",
    "    df1 = df[df.columns[::-1]]\n",
    "    #print(df1)\n",
    "    \n",
    "    # Get only floats so we can do operations on entire rows\n",
    "    #df2 = df1[df1[1:]]\n",
    "    #df1 = df1.select_dtypes(include=['float64'])\n",
    "    #df1 = df1[df1.select_dtypes(include=['float64'])]\n",
    "    \n",
    "    # Make decay vector, and reverse it, and make it a ndarray\n",
    "    time = np.arange(len(df1.columns)-3)\n",
    "    decay_list = [np.exp(-t / decay_rate) for t in time]\n",
    "    decay_list.reverse()\n",
    "    decay_array = np.asarray(decay_list)\n",
    "    print(type(decay_array[0]))\n",
    "    \n",
    "    a = df1.iloc[:, 3:]\n",
    "    #an = np.asarray(a)\n",
    "    #print(an)\n",
    "    print(type(a))\n",
    "   \n",
    "    #print(a)\n",
    "    \n",
    "    df2 = decay_array.T * np.asmatrix(a)\n",
    "    \n",
    "    # Put the columns back in their original order\n",
    "    df3 = df2[df2.columns[::-1]]\n",
    "    \n",
    "    return df3\n",
    "main(file_name, 400, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_csv(df, filename=None, num_results=None, decay_rate=None):\n",
    "    if filename == None:\n",
    "        filename = file_name\n",
    "    if num_results == None:\n",
    "        num_results = 100\n",
    "    if decay_rate == None:\n",
    "        decay_rate = 25\n",
    "    \n",
    "    path_out = root + file_name[:-4] + '_' + str(num_results) + '_normalized_decayed_at_' + str(decay_rate) + '.csv'\n",
    "    \n",
    "    df1 = df.round(3)\n",
    "    df1.to_csv(path_out, index_label='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "code_folding": [
     5,
     11,
     16,
     21,
     27
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(file_name=None, num_results=None,  decay_rate=None):\n",
    "    if file_name == None:\n",
    "        file_name = filename\n",
    "    if num_results == None:\n",
    "        num_results = 100\n",
    "    if decay_rate == None:\n",
    "        decay_rate == 25\n",
    "    \"\"\"\n",
    "    Take a CSV file worth of data, get the top results, apply exponential decay,\n",
    "    and write the decayed scores back to CSV\n",
    "\n",
    "    The file should:\n",
    "        Be a CSV\n",
    "        Have a 1st column named 'title'\n",
    "        Have subsequent columns as single year values - i.e. 1900\n",
    "        \n",
    "    Run this 'main' script from the root scaling-science folder\n",
    "        \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: string\n",
    "        The name of the CSV file\n",
    "    \n",
    "    num_results: int\n",
    "        The number of top results you would like to return\n",
    "   \n",
    "    decay_rate: int\n",
    "        The rate at which you would like scores to decay. \n",
    "        **Note - smaller decay_rate values make scores decay *quicker*\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CSV of floats with same column structure as that which was put in\n",
    "        Where each float represents the decayed impact value for that paper in that year\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #df = data_prep(file_name, num_results)\n",
    "    df = get_data(file_name)\n",
    "    df1 = add_aggregate_cols(df)\n",
    "    df2 = clean_for_viz(df1, num_results)\n",
    "    df_decay = decay(df, decay_rate)\n",
    "    df_norm = scale_linear_bycolumn(df_decay, high=100.0, low=0.0)\n",
    "    #df_norm = normalize(df_decay)\n",
    "    write_to_csv(df_norm, file_name, num_results, decay_rate)\n",
    "    print('Finished writing results')\n",
    "    return df_decay\n",
    "    #return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-36412a0d3b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%timeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-267-a451033017f2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(file_name, num_results, decay_rate)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mdf_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mdf_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_linear_bycolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#df_norm = normalize(df_decay)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-264-f5499475c44c>\u001b[0m in \u001b[0;36mdecay\u001b[0;34m(df, decay_rate)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecay_array\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Put the columns back in their original order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataFrame'"
     ]
    }
   ],
   "source": [
    "#%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_iterated_to_csv(df, num_results=None, decay_rate=None):\n",
    "    if num_results == None:\n",
    "        num_results = 400\n",
    "    if decay_rate == None:\n",
    "        decay_rate = 25\n",
    "        \n",
    "    path_out = '/Users/timholdsworth/code/scaling-science/Data/' + file_name[:-4] + '_' + str(num_results) + '_results_decayed_at_' + str(decay_rate) + '.csv'\n",
    "    df1 = df.round(3)\n",
    "    df1.to_csv(path_out, index_label='title')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through decay values and write them all to one csv file\n",
    "def iterate_through_decay_vals():\n",
    "    col_name = str(year) + str(decay_value)\n",
    "    #for decay_rate in range(0, 100, 5):\n",
    "        #main(file_name, 100, 5, decay_rate)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
