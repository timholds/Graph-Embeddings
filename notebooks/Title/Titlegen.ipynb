{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_df(query, graph):\n",
    "    print(\"Starting query...\", end=\" \")\n",
    "    query_start_time = time.time()\n",
    "    df = graph.run(query).to_data_frame()\n",
    "    print(\"Done ({:.2f} minutes).\".format((time.time()-query_start_time)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = Graph( \"bolt://matlaber10.media.mit.edu:7687\", auth=('neo4j','myneo'))\n",
    "graph = Graph( \"bolt://neo4j-magtwo:7687\", auth=('neo4j','myneo'))\n",
    "# print(\"Connected to graph database with {:,} nodes and {:,} relationships!\".format(\n",
    "#     graph.database.primitive_counts['NumberOfNodeIdsInUse'], \n",
    "#     graph.database.primitive_counts['NumberOfRelationshipIdsInUse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_query(venue):\n",
    "    query =  \"\"\"\n",
    "    MATCH (a:Author)-[:AUTHORED]-(q:Quanta)\n",
    "    WHERE q.venue = '{}'\n",
    "    RETURN COLLECT(q.title) AS titles\n",
    "    \"\"\".format(venue)\n",
    "    return query\n",
    "\n",
    "def gen_query(venue):\n",
    "    query =  \"MATCH (q:Quanta)-[:PUBLISHED_IN_VENUE]->(v:Venue) WHERE v.name = '{}' RETURN collect(q.title) as titles\".format(venue)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query... Done (0.58 minutes).\n",
      "Starting query... Done (1.60 minutes).\n",
      "Starting query... Done (0.10 minutes).\n",
      "Starting query... Done (1.84 minutes).\n",
      "Starting query... Done (1.58 minutes).\n"
     ]
    }
   ],
   "source": [
    "venues = top_42\n",
    "\n",
    "for venue in venues:\n",
    "    query = gen_query(venue)\n",
    "    df = query_to_df(query, graph)\n",
    "#     df.to_csv('Train_/{}_titles.csv'.format(venue), index = False, encoding = \"UTF-8\")\n",
    "    df.to_csv('/tmp/data/titles/Train/{}_titles.csv'.format(venue), index = False, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "venues = top_42\n",
    "\n",
    "for venue in venues:\n",
    "    df_titles = pd.read_csv('/tmp/data/titles/Train/{}_titles.csv'.format(venue))\n",
    "    title_list = df_titles.iloc[0]['titles']\n",
    "    texts = ast.literal_eval(title_list)\n",
    "    print('Number of titles in ', venue, ':', len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Titles Across All Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brendan/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = ['Cell', 'Nature', 'Nature Biotechnology','Proceedings of the National Academy of Sciences of the United States of America','Science']\n",
    "top_10 = ['Cell', 'Nature', 'Nature Biotechnology','Proceedings of the National Academy of Sciences of the United States of America','Science', 'Journal of the American Chemical Society', 'JAMA', 'The New England Journal of Medicine', 'Nature Genetics', 'Neuron']\n",
    "top_42 = ['Angewandte Chemie','Blood','Cancer Cell','Cancer Discovery','Cancer Research','Cell','Cell Host & Microbe','Cell Metabolism','Cell Stem Cell','Chemistry & Biology','The EMBO Journal','Genes & Development','Immunity','Journal of Neurology','Journal of the American Chemical Society','JAMA','Journal of Biological Chemistry','Journal of Cell Biology','Journal of Clinical Investigation','Journal of Experimental Medicine','Journal of Medicinal Chemistry','The Lancet','Nature Cell Biology','Nature Chemical Biology','Nature Chemistry','Nature Medicine','Nature Methods','Nature','Nature Biotechnology','The New England Journal of Medicine','Neuron','Nature Genetics','Nature Immunology','Nature Neuroscience','Nature Structural & Molecular Biology','PLOS Biology','PLOS Genetics','PLOS Pathogens','Proceedings of the National Academy of Sciences of the United States of America','Science Signaling','Science Translational Medicine','Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591660"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def gen_titles_concat(venues, n_gen=10, num_epochs_=10, batch_size_=128, rnn_size_=128, rnn_layers_=2):\n",
    "    texts = []\n",
    "    for venue in venues: \n",
    "        print('Adding Venue: ', venue)\n",
    "        df_titles = pd.read_csv('~/data/titles/Train/{}_titles.csv'.format(venue))    \n",
    "        title_list = df_titles.iloc[0]['titles']\n",
    "        titles = ast.literal_eval(title_list)\n",
    "        texts.extend(titles)\n",
    "        print('Number of titles for', venue, ':', len(titles))\n",
    "\n",
    "    print('Total number of titles:', len(texts))\n",
    "    \n",
    "    textgen = textgenrnn()\n",
    "    name_ = str(rnn_size_) + \"_\" + str(rnn_layers_)\n",
    "    textgen.train_on_texts(texts, num_epochs=num_epochs_, gen_epochs=1, new_model=True,\n",
    "                           save_epochs=1, batch_size=batch_size_, verbose=1, word_level=True,\n",
    "                          name=name_, rnn_size=rnn_size_, rnn_layers=rnn_layers_)\n",
    "    textgen.generate_to_file('/u/skokada/data/titles/Gen/{}_gen.txt'.format(name_),\n",
    "                            n=n_gen, \n",
    "                            temperature=[i/n_gen for i in range(n_gen)],\n",
    "                            max_gen_length=100,\n",
    "                            progress=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "venues = top_42\n",
    "for rnn_size_ in [32, 64, 128, 256]:\n",
    "    for rnn_layers_ in [2, 3]:\n",
    "        name = str(rnn_size_) + \"_\" + str(rnn_layers_)\n",
    "        oldStdout = sys.stdout\n",
    "        file = open('/u/skokada/data/titles/Gen/{}_log.txt'.format(name),'w')\n",
    "        sys.stdout = file\n",
    "        gen_titles_concat(venues, rnn_size_ = rnn_size_, rnn_layers_ = rnn_layers_)\n",
    "        file.close()\n",
    "        sys.stdout = oldStdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Titles at Each Epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for rnn_size_ in [32, 64, 128, 256]:\n",
    "    for rnn_layers_ in [2, 3]:\n",
    "        name = str(rnn_size_) + \"_\" + str(rnn_layers_)\n",
    "        ids.append(name)\n",
    "for id in ids:\n",
    "    with open('/u/skokada/data/titles/Gen/{}/{}_titles.txt'.format(id, id), 'w') as f:\n",
    "        for epoch in range(1, 10):\n",
    "            textgen = textgenrnn(weights_path = '/u/skokada/data/titles/Gen/{}/{}_weights_epoch_{}.hdf5'.format(id, id, epoch),\n",
    "                                vocab_path = '/u/skokada/data/titles/Gen/{}/{}_vocab.json'.format(id, id),\n",
    "                                config_path = '/u/skokada/data/titles/Gen/{}/{}_config.json'.format(id, id))\n",
    "            temperatures=[i/10 for i in range(1, 11)]\n",
    "            f.write('Epoch: ' + str(epoch) + '\\n')\n",
    "            for t in temperatures:\n",
    "                f.write(\"Temperature: \" + str(t) + '\\n')\n",
    "                titles = textgen.generate(n=3, temperature=t, progress=False, return_as_list=True)\n",
    "                for title in titles:\n",
    "                    f.write(title + '\\n')\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Individual Journal Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "venues = top_42\n",
    "for venue in venues:\n",
    "    oldStdout = sys.stdout\n",
    "    file = open('/u/skokada/data/titles/Gen/{}_log.txt'.format(venue), 'w')\n",
    "    sys.stdout = file\n",
    "    gen_titles(venue)\n",
    "    sys.stdout = oldStdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def gen_titles(venue, n_gen=20, epochs=20, batch=128):\n",
    "#     df_titles = pd.read_csv('Train/{}_titles.csv'.format(venue))\n",
    "#     df_titles = pd.read_csv('/tmp/data/titles/Train/{}_titles.csv'.format(venue))\n",
    "    df_titles = pd.read_csv('~/data/titles/Train/{}_titles.csv'.format(venue))    \n",
    "    title_list = df_titles.iloc[0]['titles']\n",
    "    texts = ast.literal_eval(title_list)\n",
    "    print('Venue: ', venue)\n",
    "    print('Number of titles:', len(texts))\n",
    "    textgen = textgenrnn()\n",
    "    textgen.train_on_texts(texts, num_epochs=epochs, gen_epochs=epochs+1, batch_size=batch, verbose=1)\n",
    "    textgen.save('/u/skokada/data/titles/Gen/{}.hdf5'.format(venue))\n",
    "    \n",
    "#     textgen.generate_to_file('Gen/{}_generated.txt'.format(venue),\n",
    "#                     n=n_gen, \n",
    "#                     temperature=[.2 for i in range(len(texts))],\n",
    "#                     max_gen_length=100,\n",
    "#                     progress=False)\n",
    "    textgen.generate_to_file('/u/skokada/data/titles/Gen/{}_generated.txt'.format(venue),\n",
    "                            n=n_gen, \n",
    "                            temperature=[i/n_gen for i in range(n_gen)],\n",
    "                            max_gen_length=100,\n",
    "                            progress=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
